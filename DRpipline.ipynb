{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1c2f3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27e413af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms, models\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84072381",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                           f1_score, confusion_matrix, classification_report,\n",
    "                           roc_auc_score, cohen_kappa_score)\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec0e9adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self):\n",
    "        #dataset pathways\n",
    "        self.data_dir = Path('aptos2019-blindness-detection')\n",
    "        self.train_csv = self.data_dir/'train.csv'\n",
    "        self.train_images_dir = self.data_dir/'train_images'\n",
    "        self.test_images_dir = self.data_dir/'test_images'\n",
    "\n",
    "        #Model path\n",
    "        self.model_dir = Path('savemodels')\n",
    "        self.model_features = Path('extracted_features')\n",
    "        self.model_results = Path('results')\n",
    "\n",
    "        #Create Directories \n",
    "        for dir_path in [self.model_dir, self.model_features, self.model_results]:\n",
    "            dir_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Hyperparameters\n",
    "        self.batch_size = 16\n",
    "        self.num_epochs = 10\n",
    "        self.learning_rate = 5e-5\n",
    "        self.num_classes = 5 #(0-4 severity)\n",
    "        self.img_size = (512, 512) # for highlightling retina images\n",
    "\n",
    "        # Unfreezing strategy\n",
    "        self.unfreeze_blocks = {\n",
    "            'resnet50': ['layer4', 'fc'],\n",
    "            'inception_v3': ['Mixed_7c', 'Mixed_7b', 'Mixed_7a', 'fc'],\n",
    "            'densenet121': ['denseblock4', 'classifier']\n",
    "        }\n",
    "\n",
    "        # Models\n",
    "        self.pretrained_models = {\n",
    "            'resnet50': models.resnet50,\n",
    "            'densenet121': models.densenet121,\n",
    "            'inceptionV3': models.inception_v3\n",
    "        }\n",
    "\n",
    "        # XGBoost parameters\n",
    "        self.xgb_params = {\n",
    "            'objective': 'multi:softmax',\n",
    "            'num_class': 5,\n",
    "            'max_depth': 6,\n",
    "            'learning_rate': 0.1,\n",
    "            'n_estimators': 100,\n",
    "            'subsample': 0.8,\n",
    "            'colsample_bytree': 0.8,\n",
    "            'random_state': 42,\n",
    "            'n_jobs': -1\n",
    "        }\n",
    "\n",
    "        self.n_splits = 5\n",
    "        self.random_seed = 42\n",
    "\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        def to_dict(self):\n",
    "            return {k:v for k,v in self.__dict__.items() if not k.startswith('_')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4844f3c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DataAugmentation:\n",
    "    \"performing Data augmentation for our images\"\n",
    "\n",
    "    @staticmethod\n",
    "    def get_train_transform():\n",
    "\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((512,512)),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomVerticalFlip(p=0.5),\n",
    "            transforms.RandomRotation(degrees=30),\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "            transforms.RandomAffine(degrees=0, translate=(0.1,0.1), scale=(0.9,1.1)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_val_transform():\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((512,512)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    \n",
    "    @staticmethod\n",
    "    def preprocess_image(image_path):\n",
    "        transfrom = transforms.Compose([\n",
    "            transforms.Resize((512,512)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        return transfrom(image).unsqueeze(0)\n",
    "11        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4cab1cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomAptos(Dataset):\n",
    "    #Customizing the AptosDataset for our use\n",
    "    def __init__(self, dataframe, image_dir, transform = None, is_test = False):\n",
    "\n",
    "        self.dataframe = dataframe\n",
    "        self.image_dir = Path(image_dir)\n",
    "        self.transform = transform\n",
    "        self.is_test = is_test\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.dataframe.iloc[idx]['id_code']\n",
    "    \n",
    "        # Handle different image extensions\n",
    "        image_paths = [\n",
    "            self.image_dir / f\"{img_name}.png\",\n",
    "            self.image_dir / f\"{img_name}.jpg\",\n",
    "            self.image_dir / f\"{img_name}.jpeg\"\n",
    "        ]\n",
    "\n",
    "        image_path = next((p for p in image_paths if p.exists()), None)\n",
    "        if image_path is None:\n",
    "            raise FileNotFoundError(f\"Image not found for {img_name}\")\n",
    "    \n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        if self.is_test:\n",
    "            return image, img_name\n",
    "            \n",
    "        label = self.dataframe.iloc[idx]['diagnosis']\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17fa34ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DRModelManager:\n",
    "    #Manages multiple pre-trained models for diabetic retinopathy\n",
    "\n",
    "    def __init__(self, config, model_name):\n",
    "        self.config = config\n",
    "        self.model_name = model_name\n",
    "        self.device = config.device\n",
    "        self.model = None\n",
    "        self.feature_extractor = None\n",
    "        self._initialize_model_finetune()\n",
    "\n",
    "    def _initialize_model_finetune(self):\n",
    "        \"\"\"Initialize pre-trained model with fine-tuning on last blocks only\"\"\"\n",
    "        \n",
    "        if self.model_name == 'resnet50':\n",
    "            self._initialize_resnet50_finetune()\n",
    "            \n",
    "        elif self.model_name == 'inceptionV3':\n",
    "            self._initialize_inception_v3_finetune()\n",
    "            \n",
    "        elif self.model_name == 'densenet121':\n",
    "            self._initialize_densenet121_finetune()\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f\"Model {self.model_name} not supported\")\n",
    "        \n",
    "        self.model.to(self.device)\n",
    "        \n",
    "        # Create feature extractor (all layers except the final classifier)\n",
    "        self._feature_extractor()\n",
    "    \n",
    "    def _initialize_resnet50_finetune(self):\n",
    "        \"\"\"Fine-tune ResNet50: Freeze all, unfreeze layer4 and FC\"\"\"\n",
    "        self.model = models.resnet50(pretrained = True)\n",
    "\n",
    "        # CONCEPT: Freezing the Backbone\n",
    "        # We start by turning off gradient calculation for ALL layers.\n",
    "        # This locks the weights of the feature extractor (layers 1-3)\n",
    "        # so they act as a static \"retinal feature detector\"\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        for param in self.model.layer4.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        # Also unfreeze the BatchNorm layers in the last block\n",
    "        for module in self.model.layer4.modules():\n",
    "            if isinstance(module, nn.BatchNorm2d):\n",
    "                module.train()  # Set to training mode\n",
    "                for param in module.parameters():\n",
    "                    param.requires_grad = True\n",
    "\n",
    "        num_feature = self.model.fc.in_features\n",
    "        self.model.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(num_feature, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, self.config.num_classes)\n",
    "        )\n",
    "\n",
    "        for param in self.model.fc.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    def _initialize_inception_v3_finetune(self):\n",
    "        \"\"\"Fine-tune InceptionV3: Unfreeze Mixed_7 blocks\"\"\"\n",
    "        # Note: aux_logits=True is required for stable Inception training\n",
    "        self.model = models.inception_v3(pretrained=True, aux_logits=False)\n",
    "\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "        # InceptionV3 architecture: Unfreeze from Mixed_7c onward (last few blocks)\n",
    "        # Mixed_6a to Mixed_7c are the later blocks\n",
    "\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if 'Mixed_7' in name or 'Mixed_6e' in name or 'Mixed_6d' in name: # type: ignore\n",
    "                param.requires_grad = True\n",
    "            if 'bn' in name or 'BatchNorm' in name:  # Unfreeze BatchNorm in unfrozen blocks\n",
    "                if 'Mixed_7' in name or 'Mixed_6' in name:\n",
    "                    param.requires_grad = True\n",
    "    \n",
    "    # Replace the final FC layer\n",
    "        num_features = self.model.fc.in_features\n",
    "        self.model.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(num_features, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, self.config.num_classes)\n",
    "        )\n",
    "        \n",
    "        # Set FC layer to trainable\n",
    "        for param in self.model.fc.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    def _initialize_densenet121_finetune(self):\n",
    "        \"\"\"Fine-tune DenseNet121: only train last dense block\"\"\"\n",
    "        self.model = models.densenet121(pretrained=True)\n",
    "        \n",
    "        # FREEZE ALL LAYERS FIRST\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # DenseNet121: Unfreeze only the last dense block (denseblock4)\n",
    "        # and transition layer before it\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if 'denseblock4' in name or 'norm5' in name:\n",
    "                param.requires_grad = True\n",
    "            if 'transition3' in name:  # The transition before last block\n",
    "                param.requires_grad = True\n",
    "        \n",
    "        # Unfreeze BatchNorm layers in the unfrozen blocks\n",
    "        for name, module in self.model.named_modules():\n",
    "            if isinstance(module, nn.BatchNorm2d):\n",
    "                if 'denseblock4' in name or 'norm5' in name:\n",
    "                    module.train()\n",
    "                    for param in module.parameters():\n",
    "                        param.requires_grad = True\n",
    "        \n",
    "        # Replace the classifier\n",
    "        num_features = self.model.classifier.in_features\n",
    "        self.model.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(num_features, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, self.config.num_classes)\n",
    "        )\n",
    "        \n",
    "        # Set classifier to trainable\n",
    "        for param in self.model.classifier.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    def _feature_extractor(self):\n",
    "        \"\"\"Creates a version of the model that outputs embeddings\"\"\"\n",
    "        if self.model_name == 'resnet50':\n",
    "            # Original ResNet50 structure:\n",
    "            # [conv1, bn1, relu, maxpool, layer1, layer2, layer3, layer4, avgpool, fc]\n",
    "\n",
    "            # We take everything EXCEPT the final FC layer:\n",
    "            self.feature_extractor = nn.Sequential(*list(self.model.children())[:-1])\n",
    "            # This gives us: [conv1 → layer4 → avgpool]\n",
    "            # Output shape: (batch_size, 2048, 1, 1) after avgpool\n",
    "        \n",
    "        # InceptionV3 has different structure\n",
    "        # We need to add AdaptiveAvgPool2d because Inception's pooling might vary\n",
    "        elif self.model_name == 'inception_v3':\n",
    "            self.feature_extractor = nn.Sequential(\n",
    "                *list(self.model.children())[:-1],\n",
    "                nn.AdaptiveAvgPool2d((1,1))\n",
    "            )\n",
    "        # Output shape: (batch_size, 2048, 1, 1)\n",
    "\n",
    "        # DenseNet structure is different: features + classifier\n",
    "        elif self.model_name == 'densenet121':\n",
    "            self.feature_extractor = nn.Sequential(\n",
    "                self.model.features,\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.AdaptiveAvgPool2d((1,1))\n",
    "            )\n",
    "        # Output shape: (batch_size, 1024, 1, 1)\n",
    "\n",
    "        #Before Extraction of(CNN Output):\n",
    "        #For a batch of 16 images: Shape: (16, 2048, 7, 7)\n",
    "        # 2048 channels, 7x7 spatial grid\n",
    "\n",
    "        #After AdaptiveAvgPool2d((1,1)):\n",
    "        #Shape: (16, 2048, 1, 1)  # Each channel averaged to single value\n",
    "\n",
    "        #Shape: (16, 2048, 1, 1)  # Each channel averaged to single value\n",
    "        #Shape: (16, 2048)  # 2048-dimensional feature vector per image\n",
    "\n",
    "        self.feature_extractor.to(self.device)\n",
    "\n",
    "    def print_trainable_parameters(self):\n",
    "        \"\"\"Print which layers are trainable - useful for debugging\"\"\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Trainable parameters for {self.model_name}:\")\n",
    "        print('='*60)\n",
    "\n",
    "        total_parameter = 0\n",
    "        trainable_parameter = 0 \n",
    "\n",
    "        for name, param in self.model.named_parameters():\n",
    "            total_parameter += param.numel()\n",
    "            if param.requires_grad:\n",
    "                trainable_parameter += param.numel()\n",
    "                print(f\"✓ TRAINABLE: {name}\")\n",
    "            else:\n",
    "                print(f\"  Frozen: {name}\")\n",
    "        \n",
    "        print(f\"\\nTotal parameters: {total_parameter:,}\")\n",
    "        print(f\"Trainable parameters: {trainable_parameter:,}\")\n",
    "        print(f\"Percentage trainable: {100 * trainable_parameter / total_parameter:.2f}%\")\n",
    "        print('='*60)\n",
    "        \n",
    "        return trainable_parameter, total_parameter\n",
    "    \n",
    "    def get_model(self):\n",
    "        return self.model\n",
    "    \n",
    "    def get_feature_extractor(self):\n",
    "        return self.feature_extractor\n",
    "    \n",
    "    def save_model(self, path):\n",
    "        \"Save the important parameters and model details to use even after the training is done\"\n",
    "\n",
    "        trainable_names = []\n",
    "        trainable_names = [name for name, p in self.model.named_parameters() if p.requires_grad]\n",
    "\n",
    "        torch.save({\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'model_name': self.model_name,\n",
    "            'config': self.config.to_dict(),\n",
    "            'trainable_layers': trainable_names,\n",
    "            'feature_extractor_state_dict': self.feature_extractor.state_dict()\n",
    "        }, path)\n",
    "                \n",
    "    def load_model(self, path):\n",
    "        #Loading the saved model\n",
    "        checkpoint = torch.load(path, map_location= self.device)\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "        #loading the trainable parameter if in the model\n",
    "        if 'trainable_layers' in checkpoint:\n",
    "            # First freeze all\n",
    "            for param in self.model.parameters():\n",
    "                param.requires_grad = False\n",
    "            # Then unfreeze saved trainable layers\n",
    "            for name, param in self.model.named_parameters():\n",
    "                if name in checkpoint['trainable_layers']:\n",
    "                    param.requires_grad = True\n",
    "\n",
    "        return self.model\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "46f9be39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DRTrainer:\n",
    "    \"Training engine for our fine tune CNNs\"\n",
    "\n",
    "    def __init__(self, config, model_manager):\n",
    "        self.config = config\n",
    "        self.model_manager = model_manager\n",
    "        self.model = self.model_manager.get_model()\n",
    "        self.device = self.config.device\n",
    "\n",
    "        #Printing the Trainable parameter information\n",
    "        self.model_manager.print_trainable_parameters()\n",
    "\n",
    "        training_params = [p for p in self.model.parameters() if p.requires_grad]\n",
    "\n",
    "        if training_params == 0:\n",
    "            raise ValueError(\"No training parameters found. Check the fine tuning.\")\n",
    "        \n",
    "        print(f\"\\nOptimizing {len(training_params)} parameter groups\")\n",
    "        \n",
    "        # Different learning rates for fine-tuned layers vs new layers\n",
    "        # Higher LR for new layers, lower LR for fine-tuned pretrained layers\n",
    "        \n",
    "        # Group parameters by type\n",
    "        new_layers = []\n",
    "        finetune_layers = []\n",
    "        \n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                if 'fc' in name or 'classifier' in name:\n",
    "                    new_layers.append(param)  # New classifier layers\n",
    "                else:\n",
    "                    finetune_layers.append(param)  # Fine-tuned pretrained layers\n",
    "        \n",
    "        # Create parameter groups with different learning rates\n",
    "        # We pass these groups to the optimizer\n",
    "        param_groups = [\n",
    "            {'params': finetune_layers, 'lr': config.learning_rate * 0.1},\n",
    "            {'params': new_layers, 'lr': config.learning_rate}  \n",
    "        ]\n",
    "        self.optimizer = optim.AdamW(param_groups, lr=config.learning_rate)\n",
    "        \n",
    "        #lr scheduler for countinuouly chaning learning and then restarting with higher after some epochs\n",
    "        # Scheduler: Cosine Annealing with Warm Restarts prevents getting stuck in local minima\n",
    "        self.shecduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "            self.optimizer, T_0=5, T_mult=2, eta_min=1e-6\n",
    "        )\n",
    "\n",
    "        # Loss fucntion with class wieght imbalance\n",
    "        self.criterion = self._get_weighted_loss()\n",
    "\n",
    "        #initialize GradScaler for mixed precision training if CUDA is available\n",
    "        self.scaler = torch.cuda.amp.GradScaler() if torch.cuda.is_available() else None\n",
    "\n",
    "        self.history = {\n",
    "            'train_loss': [], 'train_acc': [],\n",
    "            'val_loss': [], 'val_acc': [],\n",
    "            'learning_rates': []\n",
    "        }\n",
    "\n",
    "    def _get_weighted_loss(self):\n",
    "        \"\"\"\n",
    "    Dynamically calculates class weights based on the training data.\n",
    "    Higher weights are assigned to rare classes (like Severe DR) to prevent bias.\n",
    "    \"\"\"\n",
    "        #Used to assign more weight to less frequency labels in the dataset to avoid baises\n",
    "        #Calculate the weight of each class by - Total sample / no.of classes * count of item in class i\n",
    "        if not self.config.train_csv.exists():\n",
    "            print(\"Warning: Train CSV not found for weight calc. Using default weights.\")\n",
    "            return nn.CrossEntropyLoss()\n",
    "        \n",
    "\n",
    "        df = pd.read_csv(self.config.train_csv)\n",
    "        # Count samples per class\n",
    "        counts = df[\"diagnosis\"].value_counts().sort_index()\n",
    "        class_counts = counts.values\n",
    "        # Calculate weights: Total / (Num_Classes * Class_Count)\n",
    "        # This is the standard \"Balanced\" formula\n",
    "        total_samples = sum(class_counts)\n",
    "        num_classes = len(class_counts)\n",
    "        weights = total_samples / (num_classes * class_counts)\n",
    "\n",
    "        class_weights = torch.tensor(weights, dtype=torch.float32)\n",
    "        #trunsout to be tensor([0.4058, 1.9795, 0.7331, 3.7948, 2.4827])\n",
    "        #Normalize weights\n",
    "        class_weights = class_weights / class_weights.sum()\n",
    "        class_weights = class_weights.to(self.device)\n",
    "\n",
    "        print(f\"Computed Class Weights: {class_weights}\")\n",
    "        # Expected Output for APTOS: tensor([0.05, 0.22, 0.08, 0.41, 0.24]) approx\n",
    "        return nn.CrossEntropyLoss(weight= class_weights)\n",
    "    \n",
    "    def train_epoch(self, train_loader, epoch):\n",
    "        self.model.train()\n",
    "\n",
    "        #Handling the BatchNorm blocks in fine tunning to make sure they are in traning mode\n",
    "        for name, module in self.model.named_modules():\n",
    "            if isinstance(module, nn.BatchNorm2d) and hasattr(module, 'weight'):\n",
    "                if module.weight.requires_grad:\n",
    "                    module.train()\n",
    "\n",
    "        running_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{self.config.num_epochs}')\n",
    "        for batch_idx, (inputs, labels) in enumerate(pbar):\n",
    "            inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "\n",
    "            #Handling the InceptionV3 duo outputs during training (output, aux_output)\n",
    "\n",
    "            if self.model_manager.model_name == 'inceptionV3':\n",
    "                outputs, aux_outputs = self.model(inputs)\n",
    "                # outputs: Main prediction from final layer\n",
    "                # aux_outputs: Auxiliary prediction from middle layer\n",
    "\n",
    "                loss1 = self.criterion(outputs, labels)\n",
    "                loss2 = self.criterion(aux_outputs, labels)\n",
    "                loss = loss1 + 0.4 * loss2  # Weighted sum as in original paper\n",
    "            else:\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "\n",
    "            # CONCEPT: Gradient Clipping\n",
    "            # Fine-tuning can sometimes produce large gradients that destabilize the\n",
    "            # pre-trained weights. We clip the gradient norm to 1.0 to ensure smooth updates.\n",
    "            #for faster training we use mix precision training where we use FP16 and Fp32\n",
    "            if self.scaler:  # If we have a GPU that supports mixed precision\n",
    "                # 1. Scale up the loss (prevents underflow)\n",
    "                self.scaler.scale(loss).backward()\n",
    "                # Loss is multiplied by e.g., 65536 before backward pass\n",
    "                \n",
    "                # 2. Unscale gradients before optimizer step\n",
    "                self.scaler.unscale_(self.optimizer)\n",
    "                # Now gradients are back to normal scale\n",
    "                \n",
    "                # 3. Clip gradients (prevent overflow)\n",
    "                torch.nn.utils.clip_grad_norm_(\n",
    "                    [p for p in self.model.parameters() if p.requires_grad], \n",
    "                    max_norm=1.0\n",
    "                )\n",
    "                \n",
    "                # 4. Optimizer step with scaling\n",
    "                self.scaler.step(self.optimizer)\n",
    "                \n",
    "                # 5. Update scale factor for next iteration\n",
    "                self.scaler.update()\n",
    "\n",
    "            else:\n",
    "                loss.backward()\n",
    "\n",
    "                #gradient Clipping \n",
    "                torch.nn.utils.clip_grad_norm_(\n",
    "                    [p for p in self.model.parameters() if p.requires_grad], \n",
    "                    max_norm=1.0)\n",
    "\n",
    "                self.optimizer.step()\n",
    "\n",
    "            #statistics\n",
    "            #running_loss: Sum of all batch losses in the current epoch\n",
    "            #Example: If 100 batches with losses [0.5, 0.4, 0.3, ...], running_loss = 0.5 + 0.4 + 0.3 + ...\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            #getting the prediction outputs where we recive 5 output and only choose max value from each iteration\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "\n",
    "            #Gettting the total correctly predicted labels in each iteration\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "            #showing the progress bar to monitor the performance\n",
    "            pbar.set_postfix({\n",
    "                'loss': running_loss / (batch_idx + 1),\n",
    "                'acc': 100. * correct / total\n",
    "            })\n",
    "\n",
    "        #Managing the loss per epcoh\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_acc = 100. * correct / total\n",
    "\n",
    "        self.history['train_loss'].append(epoch_loss)\n",
    "        self.history['train_acc'].append(epoch_acc)\n",
    "\n",
    "        return epoch_loss, epoch_acc\n",
    "    \n",
    "    def validate(self, val_loader):\n",
    "        #Performing the validation for our trained model\n",
    "        self.model.eval()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "\n",
    "                #For InceptionV3 in eval mode, no aux output\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "\n",
    "                running_loss = loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        epoch_loss = running_loss / len(val_loader)\n",
    "        epoch_acc = 100* correct/ total\n",
    "\n",
    "        self.history['val_loss'].append(epoch_loss)\n",
    "        self.history['val_acc'].append(epoch_acc)\n",
    "\n",
    "        return epoch_loss, epoch_acc, all_preds, all_labels\n",
    "    \n",
    "    def save_checkpoint(self, epoch, best_acc, save_path):\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'best_acc': best_acc,\n",
    "            'history': self.history\n",
    "        }, save_path)\n",
    "\n",
    "    def load_checkpoint(self, path):\n",
    "        ckpt = torch.load(path, map_location=self.device)\n",
    "        self.model.load_state_dict(ckpt['model_state_dict'])\n",
    "        self.optimizer.load_state_dict(ckpt['optimizer_state_dict'])\n",
    "        self.history = ckpt['history']\n",
    "        return ckpt['epoch'], ckpt['best_acc']\n",
    "        \n",
    "    def train(self, train_loader, val_loader, start_epoch=0, best_acc=0):\n",
    "        #Complete Traing loopwith fine tunning included\n",
    "\n",
    "        checkpoint_path = self.config.model_dir / f'{self.model_manager.model_name}_finetune_checkpoint.pth'\n",
    "        best_model_path = self.config.model_dir / f\"{self.model_manager.model_name}_finetune_best.pth\"\n",
    "\n",
    "        print(f\"\\nStarting fine-tunning for {self.model_manager.model_name}\")\n",
    "        print(f\"Checkpoint will be saved to: {checkpoint_path}\")\n",
    "\n",
    "        for epoch in range(start_epoch, self.config.num_epochs):\n",
    "            #Adjust learning rate if using warmup\n",
    "            if epoch < 5: #Warmpup phase\n",
    "                for param_group in self.optimizer.param_groups:\n",
    "                    param_group ['lr'] = self.config.learning_rate * (epoch + 1) / 5\n",
    "\n",
    "                    #Train\n",
    "                    train_loss, train_acc = self.train_epoch(train_loader, epoch)\n",
    "                    \n",
    "                    #Validate\n",
    "                    val_loss, val_acc, val_preds, val_labels = self.validate(val_loader)\n",
    "\n",
    "                    #Upadate the learning rate scheduler\n",
    "                    self.scheduler.step(epoch + train_loss)\n",
    "\n",
    "                    #storing learning rate\n",
    "                    current_lr = self.optimizer.param_groups[0]['lr']\n",
    "                    self.history['learning_rates'].append(current_lr)\n",
    "\n",
    "                    #Save checkpoint\n",
    "                    self.save_checkpoint(epoch, best_acc, checkpoint_path)\n",
    "\n",
    "                    #Save the best model\n",
    "                    if val_acc > best_acc:\n",
    "                        best_acc = val_acc\n",
    "                        self.model_manager.save_model(best_model_path)\n",
    "                        print(f\"New best model saved with accuracy{best_acc:.f}%\")\n",
    "\n",
    "                    print(f'/nEpoch {epoch+1}/{self.config.num_epcohs}:')\n",
    "                    print(f'Train loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
    "                    print(f'Val loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}')\n",
    "\n",
    "                    # Print learning rates for each parameter group\n",
    "                    for i, param_group in enumerate(self.optimizer.param_groups):\n",
    "                        if i == 0:\n",
    "                            print(f\"  Fine-tune LR: {param_group['lr']:.6f}\")\n",
    "                        else:\n",
    "                            print(f\"  New layers LR: {param_group['lr']:.6f}\")\n",
    "                    \n",
    "                    print(\"-\" * 60)\n",
    "                    # Load best model for final evaluation\n",
    "                self.model_manager.load_model(best_model_path)\n",
    "                print(f\"\\n✓ Fine-tuning completed for {self.model_manager.model_name}\")\n",
    "                print(f\"✓ Best validation accuracy: {best_acc:.2f}%\")\n",
    "                return self.history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "351cd3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor:\n",
    "    # Passes images through the trained CNN models (minus the final classification layer)\n",
    "    # to extract high-level feature vectors (embeddings). These vectors are then used \n",
    "    # as the input data to train the XGBoost classifier.\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.device = config.device\n",
    "\n",
    "    def extract_feature(self,model_manager, data_loader):\n",
    "        feature_extractor = model_manager.get_feature_extractor()\n",
    "        feature_extractor.eval()\n",
    "        all_features, all_labels = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in tqdm(data_loader, desc='Extracting features'):\n",
    "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "\n",
    "                features = feature_extractor(inputs)\n",
    "                features = features.view(features.size(0), -1)\n",
    "                all_features.append(features.cpu().numpy())\n",
    "                all_labels.append(labels.numpy())\n",
    "\n",
    "                return np.vstack(all_features), np.concatenate(all_labels)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ad6ce6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XGBoostTrainer:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "    #rain one XGBoost model on features from one specific CNN (e.g., just ResNet50 features).\n",
    "    def train_single_model(self, X_train, y_train, X_val, y_val):\n",
    "        model = xgb.XGBClassifier(**self.config.xgb_params)\n",
    "        model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False, early_stopping_rounds=10)\n",
    "        return model\n",
    "    #train the \"Master\" XGBoost model that sees everything.\n",
    "    def train_ensemble(self, feature_list, y_train, features_val_list, y_val):\n",
    "        X_train_combined = np.hstack(feature_list)\n",
    "        X_val_combined = np.hstack(features_val_list)\n",
    "        model = xgb.XGBClassifier(**self.config.xgb_params)\n",
    "        model.fit(X_train_combined, y_train, eval_set=[(X_val_combined, y_val)], verbose=False, early_stopping_rounds=10)\n",
    "        return model\n",
    "    \n",
    "    def evaluate_model(self, model, X_test, y_test, model_name):\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_proba = model.predict_proba(X_test)\n",
    "\n",
    "        metrics = {\n",
    "            'model_name': model_name,\n",
    "            'accuracy': accuracy_score(y_test, y_pred),\n",
    "            'f1_score': f1_score(y_test, y_pred, average='weighted'),\n",
    "            'cohen_kappa': cohen_kappa_score(y_test, y_pred),\n",
    "            'roc_auc': roc_auc_score(y_test, y_pred_proba, multi_class='ovr', average='weighted'),\n",
    "            'classification_report': classification_report(y_test, y_pred, output_dict=True)\n",
    "        }\n",
    "        return metrics, y_pred\n",
    "    \n",
    "    def save_model(self, model, model_name):\n",
    "        with open(self.config.model_dir/f'{model_name}_xgb.pkl', 'wb') as f:\n",
    "            pickle.dump(model, f)\n",
    "\n",
    "    def load_model(self, model_name):\n",
    "        with open(self.config.model_dir/ f\"{model_name}_xgb.pkl\", 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4a8438b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResultsVisualizer:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        plt.style.use('seaborn-v0_8-darkgrid')\n",
    "    \n",
    "    def plot_training_history(self, history, model_name):\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "        axes[0].plot(history['train_loss'], label='Train')\n",
    "        axes[0].plot(history['val_loss'], label='Val')\n",
    "        axes[0].set_title('Loss')\n",
    "        axes[0].legend()\n",
    "        \n",
    "        axes[1].plot(history['train_acc'], label='Train')\n",
    "        axes[1].plot(history['val_acc'], label='Val')\n",
    "        axes[1].set_title('Accuracy')\n",
    "        \n",
    "        axes[2].plot(history['learning_rates'])\n",
    "        axes[2].set_title('Learning Rate')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.config.results_dir / f\"{model_name}_history.png\")\n",
    "        plt.close()\n",
    "\n",
    "    def save_metrics_report(self, metrics_dict):\n",
    "        with open(self.config.results_dir / \"metrics_report.json\", 'w') as f:\n",
    "            json.dump(metrics_dict, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "49f9865f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiabeticRetionpathyPipeline:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.model = {}\n",
    "        self.visualizer = ResultsVisualizer(config)\n",
    "        torch.manual_seed(self.config.random_seed)\n",
    "        np.random.seed(self.config.random_seed)\n",
    "        \n",
    "    def load_and_prepare_data(self):\n",
    "        print(\"Loading APTOS 2019 dataset...\")\n",
    "        \n",
    "        # 1. Load the CSV\n",
    "        df = pd.read_csv(self.config.train_csv)\n",
    "        print(f\"Original CSV size: {len(df)}\")\n",
    "        \n",
    "        # 2. --- NEW STEP: Filter out missing images ---\n",
    "        valid_rows = []\n",
    "        # Check extensions\n",
    "        extensions = ['.png', '.jpg', '.jpeg']\n",
    "        \n",
    "        print(\"Verifying image files...\")\n",
    "        for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Checking files\"):\n",
    "            img_id = row['id_code']\n",
    "            found = False\n",
    "            \n",
    "            # Check if file exists with any valid extension\n",
    "            for ext in extensions:\n",
    "                path = self.config.train_images_dir / f\"{img_id}{ext}\"\n",
    "                if path.exists():\n",
    "                    valid_rows.append(row)\n",
    "                    found = True\n",
    "                    break\n",
    "            \n",
    "            # Optional: Print the first missing one to debug\n",
    "            if not found and len(df) - len(valid_rows) == 1:\n",
    "                print(f\"Warning: Could not find image for ID: {img_id}\")\n",
    "\n",
    "        # Create new cleaned dataframe\n",
    "        df_clean = pd.DataFrame(valid_rows)\n",
    "        print(f\"Cleaned dataset size: {len(df_clean)} (Removed {len(df) - len(df_clean)} missing files)\")\n",
    "        \n",
    "        if len(df_clean) == 0:\n",
    "            raise ValueError(\"No valid images found! Check your paths.\")\n",
    "\n",
    "        # 3. Split data (Using the CLEAN dataframe)\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        train_df, val_df = train_test_split(\n",
    "            df_clean, # Use clean df\n",
    "            test_size=0.2, \n",
    "            random_state=self.config.random_seed,\n",
    "            stratify=df_clean['diagnosis']\n",
    "        )\n",
    "        \n",
    "        # 4. Create DataLoaders (Rest of your code is same)\n",
    "        train_loader = DataLoader(\n",
    "            CustomAptos(train_df, self.config.train_images_dir, DataAugmentation.get_train_transform()),\n",
    "            batch_size=self.config.batch_size, \n",
    "            shuffle=True, \n",
    "            num_workers=0, # Keep this 0 for Windows!\n",
    "            pin_memory=True\n",
    "        )\n",
    "        \n",
    "        val_loader = DataLoader(\n",
    "            CustomAptos(val_df, self.config.train_images_dir, DataAugmentation.get_val_transform()),\n",
    "            batch_size=self.config.batch_size, \n",
    "            shuffle=False, \n",
    "            num_workers=0, # Keep this 0 for Windows!\n",
    "            pin_memory=True\n",
    "        )\n",
    "        \n",
    "        return train_loader, val_loader\n",
    "    \n",
    "    def run_pipeline(self):\n",
    "        print(\"\\n===STARTING FINE-TUNED DR DETECTION PIPELINE===\")\n",
    "        \n",
    "        #1. Train Fine-Tunned CNNs\n",
    "        train_loader, val_loader = self.load_and_prepare_data()\n",
    "\n",
    "        for model_name in self.config.pretrained_models.keys():\n",
    "            print(f\"\\n Fine-Tunnig {model_name}...\")\n",
    "            manager = DRModelManager(self.config, model_name)\n",
    "            trainer = DRTrainer(self.config, manager)\n",
    "\n",
    "            histroy = trainer.train(train_loader, val_loader)\n",
    "            self.model[model_name] = manager\n",
    "            self.visualizer.plot_training_history(histroy, model_name)\n",
    "        \n",
    "        #2. Extract features\n",
    "        print(\"/nExtracting Feature for XGBoost...\")\n",
    "        feature_extractor = FeatureExtractor(self.config)\n",
    "        all_feature = []\n",
    "\n",
    "        for model_name, manager in self.model.items():\n",
    "            feats, labels = feature_extractor.extract_feature(manager, val_loader)\n",
    "            all_feature[model_name] = {'features': feats, 'labels': labels}\n",
    "\n",
    "        # 3. Train XGBoost Ensemble\n",
    "        print(\"\\nTraining XGBoost Ensemble...\")\n",
    "        xgb_trainer = XGBoostTrainer(self.config)\n",
    "        all_metrics = {}\n",
    "        \n",
    "        from sklearn.model_selection import train_test_split\n",
    "        \n",
    "        # Train Ensemble\n",
    "        X_combined_list, X_val_combined_list = [], []\n",
    "        y_train_all, y_test_all = None, None\n",
    "        \n",
    "        for model_name in self.model.keys():\n",
    "            feats, labels = all_feature[model_name]['features'], all_feature[model_name]['labels']\n",
    "            X_tr, X_te, y_tr, y_te = train_test_split(feats, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "            \n",
    "            # Train individual XGBoost for reporting\n",
    "            xgb_model = xgb_trainer.train_single_model(X_tr, y_tr, X_te, y_te)\n",
    "            metrics, _ = xgb_trainer.evaluate_model(xgb_model, X_te, y_te, f\"{model_name}_xgb\")\n",
    "            all_metrics[f\"{model_name}_xgb\"] = metrics\n",
    "            xgb_trainer.save_model(xgb_model, model_name)\n",
    "\n",
    "            X_combined_list.append(X_tr)\n",
    "            X_val_combined_list.append(X_te)\n",
    "            if y_train_all is None: y_train_all, y_test_all = y_tr, y_te\n",
    "\n",
    "        # Train Ensemble XGBoost\n",
    "        ensemble_model = xgb_trainer.train_ensemble(X_combined_list, y_train_all, X_val_combined_list, y_test_all)\n",
    "        X_test_combined = np.hstack(X_val_combined_list)\n",
    "        metrics, _ = xgb_trainer.evaluate_model(ensemble_model, X_test_combined, y_test_all, 'ensemble_xgb')\n",
    "        all_metrics['ensemble_xgb'] = metrics\n",
    "        xgb_trainer.save_model(ensemble_model, 'ensemble')\n",
    "\n",
    "        #Final Report\n",
    "        self.visualizer.save_metrics_report(all_metrics)\n",
    "        print(\"\\n Pipeline Complete. Final Metrics:\")\n",
    "        print(json.dumps(all_metrics, indent=2))\n",
    "        return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "03ad4fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading APTOS 2019 dataset...\n",
      "Original CSV size: 3662\n",
      "Verifying image files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking files: 100%|██████████| 3662/3662 [00:00<00:00, 28194.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset size: 3662 (Removed 0 missing files)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x1968daeb020>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x1968daeb2c0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_instance = Config()\n",
    "Pipeline = DiabeticRetionpathyPipeline(config_instance)\n",
    "\n",
    "Pipeline.load_and_prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499e9235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===STARTING FINE-TUNED DR DETECTION PIPELINE===\n",
      "Loading APTOS 2019 dataset...\n",
      "Original CSV size: 3662\n",
      "Verifying image files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking files: 100%|██████████| 3662/3662 [00:00<00:00, 14128.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset size: 3662 (Removed 0 missing files)\n",
      "\n",
      " Fine-Tunnig resnet50...\n",
      "\n",
      "============================================================\n",
      "Trainable parameters for resnet50:\n",
      "============================================================\n",
      "  Frozen: conv1.weight\n",
      "  Frozen: bn1.weight\n",
      "  Frozen: bn1.bias\n",
      "  Frozen: layer1.0.conv1.weight\n",
      "  Frozen: layer1.0.bn1.weight\n",
      "  Frozen: layer1.0.bn1.bias\n",
      "  Frozen: layer1.0.conv2.weight\n",
      "  Frozen: layer1.0.bn2.weight\n",
      "  Frozen: layer1.0.bn2.bias\n",
      "  Frozen: layer1.0.conv3.weight\n",
      "  Frozen: layer1.0.bn3.weight\n",
      "  Frozen: layer1.0.bn3.bias\n",
      "  Frozen: layer1.0.downsample.0.weight\n",
      "  Frozen: layer1.0.downsample.1.weight\n",
      "  Frozen: layer1.0.downsample.1.bias\n",
      "  Frozen: layer1.1.conv1.weight\n",
      "  Frozen: layer1.1.bn1.weight\n",
      "  Frozen: layer1.1.bn1.bias\n",
      "  Frozen: layer1.1.conv2.weight\n",
      "  Frozen: layer1.1.bn2.weight\n",
      "  Frozen: layer1.1.bn2.bias\n",
      "  Frozen: layer1.1.conv3.weight\n",
      "  Frozen: layer1.1.bn3.weight\n",
      "  Frozen: layer1.1.bn3.bias\n",
      "  Frozen: layer1.2.conv1.weight\n",
      "  Frozen: layer1.2.bn1.weight\n",
      "  Frozen: layer1.2.bn1.bias\n",
      "  Frozen: layer1.2.conv2.weight\n",
      "  Frozen: layer1.2.bn2.weight\n",
      "  Frozen: layer1.2.bn2.bias\n",
      "  Frozen: layer1.2.conv3.weight\n",
      "  Frozen: layer1.2.bn3.weight\n",
      "  Frozen: layer1.2.bn3.bias\n",
      "  Frozen: layer2.0.conv1.weight\n",
      "  Frozen: layer2.0.bn1.weight\n",
      "  Frozen: layer2.0.bn1.bias\n",
      "  Frozen: layer2.0.conv2.weight\n",
      "  Frozen: layer2.0.bn2.weight\n",
      "  Frozen: layer2.0.bn2.bias\n",
      "  Frozen: layer2.0.conv3.weight\n",
      "  Frozen: layer2.0.bn3.weight\n",
      "  Frozen: layer2.0.bn3.bias\n",
      "  Frozen: layer2.0.downsample.0.weight\n",
      "  Frozen: layer2.0.downsample.1.weight\n",
      "  Frozen: layer2.0.downsample.1.bias\n",
      "  Frozen: layer2.1.conv1.weight\n",
      "  Frozen: layer2.1.bn1.weight\n",
      "  Frozen: layer2.1.bn1.bias\n",
      "  Frozen: layer2.1.conv2.weight\n",
      "  Frozen: layer2.1.bn2.weight\n",
      "  Frozen: layer2.1.bn2.bias\n",
      "  Frozen: layer2.1.conv3.weight\n",
      "  Frozen: layer2.1.bn3.weight\n",
      "  Frozen: layer2.1.bn3.bias\n",
      "  Frozen: layer2.2.conv1.weight\n",
      "  Frozen: layer2.2.bn1.weight\n",
      "  Frozen: layer2.2.bn1.bias\n",
      "  Frozen: layer2.2.conv2.weight\n",
      "  Frozen: layer2.2.bn2.weight\n",
      "  Frozen: layer2.2.bn2.bias\n",
      "  Frozen: layer2.2.conv3.weight\n",
      "  Frozen: layer2.2.bn3.weight\n",
      "  Frozen: layer2.2.bn3.bias\n",
      "  Frozen: layer2.3.conv1.weight\n",
      "  Frozen: layer2.3.bn1.weight\n",
      "  Frozen: layer2.3.bn1.bias\n",
      "  Frozen: layer2.3.conv2.weight\n",
      "  Frozen: layer2.3.bn2.weight\n",
      "  Frozen: layer2.3.bn2.bias\n",
      "  Frozen: layer2.3.conv3.weight\n",
      "  Frozen: layer2.3.bn3.weight\n",
      "  Frozen: layer2.3.bn3.bias\n",
      "  Frozen: layer3.0.conv1.weight\n",
      "  Frozen: layer3.0.bn1.weight\n",
      "  Frozen: layer3.0.bn1.bias\n",
      "  Frozen: layer3.0.conv2.weight\n",
      "  Frozen: layer3.0.bn2.weight\n",
      "  Frozen: layer3.0.bn2.bias\n",
      "  Frozen: layer3.0.conv3.weight\n",
      "  Frozen: layer3.0.bn3.weight\n",
      "  Frozen: layer3.0.bn3.bias\n",
      "  Frozen: layer3.0.downsample.0.weight\n",
      "  Frozen: layer3.0.downsample.1.weight\n",
      "  Frozen: layer3.0.downsample.1.bias\n",
      "  Frozen: layer3.1.conv1.weight\n",
      "  Frozen: layer3.1.bn1.weight\n",
      "  Frozen: layer3.1.bn1.bias\n",
      "  Frozen: layer3.1.conv2.weight\n",
      "  Frozen: layer3.1.bn2.weight\n",
      "  Frozen: layer3.1.bn2.bias\n",
      "  Frozen: layer3.1.conv3.weight\n",
      "  Frozen: layer3.1.bn3.weight\n",
      "  Frozen: layer3.1.bn3.bias\n",
      "  Frozen: layer3.2.conv1.weight\n",
      "  Frozen: layer3.2.bn1.weight\n",
      "  Frozen: layer3.2.bn1.bias\n",
      "  Frozen: layer3.2.conv2.weight\n",
      "  Frozen: layer3.2.bn2.weight\n",
      "  Frozen: layer3.2.bn2.bias\n",
      "  Frozen: layer3.2.conv3.weight\n",
      "  Frozen: layer3.2.bn3.weight\n",
      "  Frozen: layer3.2.bn3.bias\n",
      "  Frozen: layer3.3.conv1.weight\n",
      "  Frozen: layer3.3.bn1.weight\n",
      "  Frozen: layer3.3.bn1.bias\n",
      "  Frozen: layer3.3.conv2.weight\n",
      "  Frozen: layer3.3.bn2.weight\n",
      "  Frozen: layer3.3.bn2.bias\n",
      "  Frozen: layer3.3.conv3.weight\n",
      "  Frozen: layer3.3.bn3.weight\n",
      "  Frozen: layer3.3.bn3.bias\n",
      "  Frozen: layer3.4.conv1.weight\n",
      "  Frozen: layer3.4.bn1.weight\n",
      "  Frozen: layer3.4.bn1.bias\n",
      "  Frozen: layer3.4.conv2.weight\n",
      "  Frozen: layer3.4.bn2.weight\n",
      "  Frozen: layer3.4.bn2.bias\n",
      "  Frozen: layer3.4.conv3.weight\n",
      "  Frozen: layer3.4.bn3.weight\n",
      "  Frozen: layer3.4.bn3.bias\n",
      "  Frozen: layer3.5.conv1.weight\n",
      "  Frozen: layer3.5.bn1.weight\n",
      "  Frozen: layer3.5.bn1.bias\n",
      "  Frozen: layer3.5.conv2.weight\n",
      "  Frozen: layer3.5.bn2.weight\n",
      "  Frozen: layer3.5.bn2.bias\n",
      "  Frozen: layer3.5.conv3.weight\n",
      "  Frozen: layer3.5.bn3.weight\n",
      "  Frozen: layer3.5.bn3.bias\n",
      "✓ TRAINABLE: layer4.0.conv1.weight\n",
      "✓ TRAINABLE: layer4.0.bn1.weight\n",
      "✓ TRAINABLE: layer4.0.bn1.bias\n",
      "✓ TRAINABLE: layer4.0.conv2.weight\n",
      "✓ TRAINABLE: layer4.0.bn2.weight\n",
      "✓ TRAINABLE: layer4.0.bn2.bias\n",
      "✓ TRAINABLE: layer4.0.conv3.weight\n",
      "✓ TRAINABLE: layer4.0.bn3.weight\n",
      "✓ TRAINABLE: layer4.0.bn3.bias\n",
      "✓ TRAINABLE: layer4.0.downsample.0.weight\n",
      "✓ TRAINABLE: layer4.0.downsample.1.weight\n",
      "✓ TRAINABLE: layer4.0.downsample.1.bias\n",
      "✓ TRAINABLE: layer4.1.conv1.weight\n",
      "✓ TRAINABLE: layer4.1.bn1.weight\n",
      "✓ TRAINABLE: layer4.1.bn1.bias\n",
      "✓ TRAINABLE: layer4.1.conv2.weight\n",
      "✓ TRAINABLE: layer4.1.bn2.weight\n",
      "✓ TRAINABLE: layer4.1.bn2.bias\n",
      "✓ TRAINABLE: layer4.1.conv3.weight\n",
      "✓ TRAINABLE: layer4.1.bn3.weight\n",
      "✓ TRAINABLE: layer4.1.bn3.bias\n",
      "✓ TRAINABLE: layer4.2.conv1.weight\n",
      "✓ TRAINABLE: layer4.2.bn1.weight\n",
      "✓ TRAINABLE: layer4.2.bn1.bias\n",
      "✓ TRAINABLE: layer4.2.conv2.weight\n",
      "✓ TRAINABLE: layer4.2.bn2.weight\n",
      "✓ TRAINABLE: layer4.2.bn2.bias\n",
      "✓ TRAINABLE: layer4.2.conv3.weight\n",
      "✓ TRAINABLE: layer4.2.bn3.weight\n",
      "✓ TRAINABLE: layer4.2.bn3.bias\n",
      "✓ TRAINABLE: fc.1.weight\n",
      "✓ TRAINABLE: fc.1.bias\n",
      "✓ TRAINABLE: fc.2.weight\n",
      "✓ TRAINABLE: fc.2.bias\n",
      "✓ TRAINABLE: fc.5.weight\n",
      "✓ TRAINABLE: fc.5.bias\n",
      "✓ TRAINABLE: fc.6.weight\n",
      "✓ TRAINABLE: fc.6.bias\n",
      "✓ TRAINABLE: fc.9.weight\n",
      "✓ TRAINABLE: fc.9.bias\n",
      "\n",
      "Total parameters: 24,691,269\n",
      "Trainable parameters: 16,147,973\n",
      "Percentage trainable: 65.40%\n",
      "============================================================\n",
      "\n",
      "Optimizing 40 parameter groups\n",
      "Computed Class Weights: tensor([0.0432, 0.2107, 0.0780, 0.4039, 0.2642], device='cuda:0')\n",
      "\n",
      "Starting fine-tunning for resnet50\n",
      "Checkpoint will be saved to: savemodels\\resnet50_finetune_checkpoint.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  71%|███████   | 130/184 [03:50<01:36,  1.80s/it, loss=1.57, acc=37.5]"
     ]
    }
   ],
   "source": [
    "Pipeline.run_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b7de4dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code is looking in: D:\\Machine learning\\Semester Project\\Final Year Project\\Diabetic Retinotopy\\Modular Implementation\\aptos2019-blindness-detection\\train_images\n",
      "✅ Directory exists.\n",
      "First 5 files found in folder:\n",
      "['000c1434d8d7.png', '001639a390f0.png', '0024cdab0c1e.png', '002c21358ce6.png', '005b95c28852.png']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# 1. Initialize your config\n",
    "config = Config()\n",
    "\n",
    "# 2. Print where the code THINKS the images are\n",
    "print(f\"Code is looking in: {config.train_images_dir.resolve()}\")\n",
    "\n",
    "# 3. Check if that folder actually exists\n",
    "if not config.train_images_dir.exists():\n",
    "    print(\"❌ ERROR: The directory does not exist!\")\n",
    "else:\n",
    "    print(\"✅ Directory exists.\")\n",
    "    # 4. List the first 5 files to see what they look like\n",
    "    print(\"First 5 files found in folder:\")\n",
    "    print(os.listdir(config.train_images_dir)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8575660",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
