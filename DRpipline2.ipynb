{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1c2f3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pickle\n",
    "import copy\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27e413af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms, models\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84072381",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                           f1_score, confusion_matrix, classification_report,\n",
    "                           roc_auc_score, cohen_kappa_score)\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec0e9adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self):\n",
    "        #dataset pathways\n",
    "        self.data_dir = Path('aptos2019-blindness-detection')\n",
    "        self.train_csv = self.data_dir/'train.csv'\n",
    "        self.train_images_dir = self.data_dir/'train_images'\n",
    "        self.test_images_dir = self.data_dir/'test_images'\n",
    "\n",
    "        #Model path\n",
    "        self.model_dir = Path('savemodels')\n",
    "        self.model_features = Path('extracted_features')\n",
    "        self.model_results = Path('results')\n",
    "\n",
    "        #Create Directories \n",
    "        for dir_path in [self.model_dir, self.model_features, self.model_results]:\n",
    "            dir_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        self.results_dir = Path('results')\n",
    "        self.results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Hyperparameters\n",
    "        self.batch_size = 32\n",
    "        self.num_epochs = 5\n",
    "        self.learning_rate = 5e-5\n",
    "        self.num_classes = 5 #(0-4 severity)\n",
    "        self.img_size = (512, 512) # for highlightling retina images\n",
    "\n",
    "        # Unfreezing strategy\n",
    "        self.unfreeze_blocks = {\n",
    "            'resnet50': ['layer4', 'fc'],\n",
    "            'inception_v3': ['Mixed_7c', 'Mixed_7b', 'Mixed_7a', 'fc'],\n",
    "            'densenet121': ['denseblock4', 'classifier']\n",
    "        }\n",
    "\n",
    "        # Models\n",
    "        self.pretrained_models = {\n",
    "            'resnet50': models.resnet50,\n",
    "            'densenet121': models.densenet121,\n",
    "            'inceptionV3': models.inception_v3\n",
    "        }\n",
    "\n",
    "        # XGBoost parameters\n",
    "        self.xgb_params = {\n",
    "            'objective': 'multi:softmax',\n",
    "            'num_class': 5,\n",
    "            'max_depth': 6,\n",
    "            'learning_rate': 0.1,\n",
    "            'n_estimators': 100,\n",
    "            'subsample': 0.8,\n",
    "            'colsample_bytree': 0.8,\n",
    "            'random_state': 42,\n",
    "            'n_jobs': -1\n",
    "        }\n",
    "\n",
    "        self.n_splits = 5\n",
    "        self.random_seed = 42\n",
    "\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    def to_dict(self):\n",
    "        return {k:v for k,v in self.__dict__.items() if not k.startswith('_')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4844f3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataAugmentation:\n",
    "    \"performing Data augmentation for our images\"\n",
    "\n",
    "    @staticmethod\n",
    "    def get_train_transform():\n",
    "\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((512,512)),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomVerticalFlip(p=0.5),\n",
    "            transforms.RandomRotation(degrees=30),\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "            transforms.RandomAffine(degrees=0, translate=(0.1,0.1), scale=(0.9,1.1)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_val_transform():\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize((512,512)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    \n",
    "    @staticmethod\n",
    "    def preprocess_image(image_path):\n",
    "        transfrom = transforms.Compose([\n",
    "            transforms.Resize((512,512)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        return transfrom(image).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cab1cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomAptos(Dataset):\n",
    "    #Customizing the AptosDataset for our use\n",
    "    def __init__(self, dataframe, image_dir, transform = None, is_test = False):\n",
    "\n",
    "        self.dataframe = dataframe\n",
    "        self.image_dir = Path(image_dir)\n",
    "        self.transform = transform\n",
    "        self.is_test = is_test\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.dataframe.iloc[idx]['id_code']\n",
    "    \n",
    "        # Handle different image extensions\n",
    "        image_paths = [\n",
    "            self.image_dir / f\"{img_name}.png\",\n",
    "            self.image_dir / f\"{img_name}.jpg\",\n",
    "            self.image_dir / f\"{img_name}.jpeg\"\n",
    "        ]\n",
    "\n",
    "        image_path = next((p for p in image_paths if p.exists()), None)\n",
    "        if image_path is None:\n",
    "            raise FileNotFoundError(f\"Image not found for {img_name}\")\n",
    "    \n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        if self.is_test:\n",
    "            return image, img_name\n",
    "            \n",
    "        label = self.dataframe.iloc[idx]['diagnosis']\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17fa34ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DRModelManager:\n",
    "    #Manages multiple pre-trained models for diabetic retinopathy\n",
    "\n",
    "    def __init__(self, config, model_name, tuning_params):\n",
    "        self.config = config\n",
    "        self.model_name = model_name\n",
    "        self.device = config.device\n",
    "        #Support for dynamic hyperparameters(Optuna)\n",
    "        #Default Params to use if tuning_params is None.\n",
    "        self.params = tuning_params if tuning_params else{\n",
    "            'fc_dim': 512,\n",
    "            'dropout':0.5,\n",
    "            'fc_layers':2\n",
    "        }\n",
    "        self.model = None\n",
    "        self.feature_extractor = None\n",
    "        self._initialize_model_finetune()\n",
    "\n",
    "    # Helper method to build variable-size classification heads\n",
    "    def _build_dynamic_head(self, in_features):\n",
    "        layers = []\n",
    "\n",
    "        #layer1\n",
    "        layers.append(nn.Dropout(self.params['dropout']))\n",
    "        layers.append(nn.Linear(in_features, self.params['fc_dim']))\n",
    "        layers.append(nn.BatchNorm1d(self.params['fc_dim']))\n",
    "        layers.append(nn.LeakyReLU(inplace=True))\n",
    "\n",
    "        #Optional Layer 2 (Controlled by tuning_params)\n",
    "        if self.params.get('fc_layers', 2) == 2:\n",
    "            layers.append(nn.Dropout(self.params['dropout'] * 0.5))\n",
    "            layers.append(nn.Linear(self.params['fc_dim'], self.params['fc_dim'] // 2))\n",
    "            layers.append(nn.BatchNorm1d(self.params['fc_dim'] // 2))\n",
    "            layers.append(nn.LeakyReLU(inplace=True))\n",
    "            last_dim = self.params['fc_dim'] // 2\n",
    "\n",
    "        else:\n",
    "            last_dim = self.params['fc_dim']\n",
    "\n",
    "        #Final Classification Layer\n",
    "        layers.append(nn.Dropout(0.2))\n",
    "        layers.append(nn.Linear(last_dim, self.config.num_classes))\n",
    "\n",
    "        \n",
    "    def _initialize_model_finetune(self):\n",
    "        \"\"\"Initialize pre-trained model with fine-tuning on last blocks only\"\"\"\n",
    "        \n",
    "        if self.model_name == 'resnet50':\n",
    "            self._initialize_resnet50_finetune()\n",
    "            \n",
    "        elif self.model_name == 'inceptionV3':\n",
    "            self._initialize_inception_v3_finetune()\n",
    "            \n",
    "        elif self.model_name == 'densenet121':\n",
    "            self._initialize_densenet121_finetune()\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f\"Model {self.model_name} not supported\")\n",
    "        \n",
    "        self.model.to(self.device)\n",
    "        \n",
    "        # Create feature extractor (all layers except the final classifier)\n",
    "        self._feature_extractor()\n",
    "    \n",
    "    def _initialize_resnet50_finetune(self):\n",
    "        \"\"\"Fine-tune ResNet50: Freeze all, unfreeze layer4 and FC\"\"\"\n",
    "        self.model = models.resnet50(pretrained = True)\n",
    "\n",
    "        # CONCEPT: Freezing the Backbone\n",
    "        # We start by turning off gradient calculation for ALL layers.\n",
    "        # This locks the weights of the feature extractor (layers 1-3)\n",
    "        # so they act as a static \"retinal feature detector\"\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        for param in self.model.layer4.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        # Also unfreeze the BatchNorm layers in the last block\n",
    "        for module in self.model.layer4.modules():\n",
    "            if isinstance(module, nn.BatchNorm2d):\n",
    "                module.train()  # Set to training mode\n",
    "                for param in module.parameters():\n",
    "                    param.requires_grad = True\n",
    "\n",
    "        # Using dynamic head builder instead of hardcoded Sequential\n",
    "        num_feature = self.model.fc.in_features\n",
    "        self.model.fc = self._build_dynamic_head(num_feature)\n",
    "\n",
    "        for param in self.model.fc.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    def _initialize_inception_v3_finetune(self):\n",
    "        \"\"\"Fine-tune InceptionV3: Unfreeze Mixed_7 blocks\"\"\"\n",
    "        # Note: aux_logits=True is required for stable Inception training\n",
    "        self.model = models.inception_v3(pretrained=True, aux_logits=True)\n",
    "\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "        # InceptionV3 architecture: Unfreeze from Mixed_7c onward (last few blocks)\n",
    "        # Mixed_6a to Mixed_7c are the later blocks\n",
    "\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if 'Mixed_7' in name or 'Mixed_6e' in name or 'Mixed_6d' in name: # type: ignore\n",
    "                param.requires_grad = True\n",
    "            if 'bn' in name or 'BatchNorm' in name:  # Unfreeze BatchNorm in unfrozen blocks\n",
    "                if 'Mixed_7' in name or 'Mixed_6' in name:\n",
    "                    param.requires_grad = True\n",
    "\n",
    "        #Handle the Auxiliary Classifier such that it does not return 1000 classe \n",
    "        #intsead it return our 5 class output\n",
    "        if self.model.AuxLogits is not None:\n",
    "            num_aux_ftrs = self.model.AuxLogits.fc.in_features\n",
    "            self.model.AuxLogits.fc = nn.Linear(num_aux_ftrs, self.config.num_classes)\n",
    "            for param in self.model.AuxLogits.fc.parameters():\n",
    "                param.requires_grad = True\n",
    "                \n",
    "        # Replace the final FC layer\n",
    "        num_features = self.model.fc.in_features\n",
    "        self.model.fc = self._build_dynamic_head(num_features)\n",
    "        \n",
    "        # Set FC layer to trainable\n",
    "        for param in self.model.fc.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    def _initialize_densenet121_finetune(self):\n",
    "        \"\"\"Fine-tune DenseNet121: only train last dense block\"\"\"\n",
    "        self.model = models.densenet121(pretrained=True)\n",
    "        \n",
    "        # FREEZE ALL LAYERS FIRST\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # DenseNet121: Unfreeze only the last dense block (denseblock4)\n",
    "        # and transition layer before it\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if 'denseblock4' in name or 'norm5' in name:\n",
    "                param.requires_grad = True\n",
    "            if 'transition3' in name:  # The transition before last block\n",
    "                param.requires_grad = True\n",
    "        \n",
    "        # Unfreeze BatchNorm layers in the unfrozen blocks\n",
    "        for name, module in self.model.named_modules():\n",
    "            if isinstance(module, nn.BatchNorm2d):\n",
    "                if 'denseblock4' in name or 'norm5' in name:\n",
    "                    module.train()\n",
    "                    for param in module.parameters():\n",
    "                        param.requires_grad = True\n",
    "        \n",
    "        # Get the original classifier's input features\n",
    "        num_features = self.model.classifier.in_features\n",
    "        \n",
    "        # **FIX: Create a new Sequential classifier and replace the old one**\n",
    "        # DenseNet's classifier is a single Linear layer, so we need to wrap our\n",
    "        # custom layers in a Sequential and assign to classifier\n",
    "        \n",
    "        # First, let's check what type of classifier we have\n",
    "        print(f\"DenseNet classifier type: {type(self.model.classifier)}\")\n",
    "        print(f\"DenseNet classifier: {self.model.classifier}\")\n",
    "        \n",
    "        # **CRITICAL: Replace the classifier with our Sequential**\n",
    "        self.model.classifier = self._build_dynamic_head(num_features)\n",
    "        \n",
    "        # Set classifier to trainable\n",
    "        for param in self.model.classifier.parameters():\n",
    "            param.requires_grad = True\n",
    "        \n",
    "        print(f\"Created new classifier with {num_features} input features\")\n",
    "        print(f\"New classifier architecture: {self.model.classifier}\")\n",
    "\n",
    "    def _feature_extractor(self):\n",
    "        \"\"\"Creates a version of the model that outputs embeddings\"\"\"\n",
    "        \n",
    "        # First, verify the model exists\n",
    "        if self.model is None:\n",
    "            raise ValueError(f\"Model is None! Check initialization for {self.model_name}\")\n",
    "        \n",
    "        if self.model_name == 'resnet50':\n",
    "            # Original ResNet50 structure:\n",
    "            # [conv1, bn1, relu, maxpool, layer1, layer2, layer3, layer4, avgpool, fc]\n",
    "\n",
    "            # We take everything EXCEPT the final FC layer:\n",
    "            self.feature_extractor = nn.Sequential(*list(self.model.children())[:-1])\n",
    "            # This gives us: [conv1 → layer4 → avgpool]\n",
    "            # Output shape: (batch_size, 2048, 1, 1) after avgpool\n",
    "        \n",
    "        # InceptionV3 has different structure\n",
    "        # We need to add AdaptiveAvgPool2d because Inception's pooling might vary\n",
    "        elif self.model_name == 'inceptionV3':\n",
    "            # --- FIX FOR INCEPTION V3 ---\n",
    "            # We cannot simple use nn.Sequential because Inception has a complex graph.\n",
    "            # Instead, we copy the model and replace the final classification layer (fc)\n",
    "            # with an Identity layer. This preserves the internal graph while outputting features.\n",
    "            \n",
    "            # 1. Create a shallow copy of the model structure to avoid breaking the original\n",
    "            self.feature_extractor = copy.deepcopy(self.model)\n",
    "            \n",
    "            # 2. Disable AuxLogits to prevent tuple outputs ((logits, aux)) during inference\n",
    "            self.feature_extractor.aux_logits = False\n",
    "            \n",
    "            # 3. Replace the final FC layer with Identity\n",
    "            # This makes the model output the 2048-dim feature vector directly\n",
    "            self.feature_extractor.fc = nn.Identity()\n",
    "\n",
    "        # DenseNet structure is different: features + classifier\n",
    "        elif self.model_name == 'densenet121':\n",
    "            # FIX: Ensure model has features attribute\n",
    "            if not hasattr(self.model, 'features'):\n",
    "                raise AttributeError(f\"DenseNet121 model doesn't have 'features' attribute\")\n",
    "            \n",
    "            self.feature_extractor = nn.Sequential(\n",
    "                self.model.features,\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.AdaptiveAvgPool2d((1,1))\n",
    "            )\n",
    "            # Output shape: (batch_size, 1024, 1, 1)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported model for feature extraction: {self.model_name}\")\n",
    "\n",
    "        #Before Extraction of(CNN Output):\n",
    "        #For a batch of 16 images: Shape: (16, 2048, 7, 7)\n",
    "        # 2048 channels, 7x7 spatial grid\n",
    "\n",
    "        #After AdaptiveAvgPool2d((1,1)):\n",
    "        #Shape: (16, 2048, 1, 1)  # Each channel averaged to single value\n",
    "\n",
    "        #Shape: (16, 2048, 1, 1)  # Each channel averaged to single value\n",
    "        #Shape: (16, 2048)  # 2048-dimensional feature vector per image\n",
    "\n",
    "        self.feature_extractor.to(self.device)\n",
    "        # Set to evaluation mode for inference\n",
    "        self.feature_extractor.eval()\n",
    "\n",
    "    def print_trainable_parameters(self):\n",
    "        \"\"\"Print which layers are trainable - useful for debugging\"\"\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Trainable parameters for {self.model_name}:\")\n",
    "        print('='*60)\n",
    "\n",
    "        total_parameter = 0\n",
    "        trainable_parameter = 0 \n",
    "\n",
    "        for name, param in self.model.named_parameters():\n",
    "            total_parameter += param.numel()\n",
    "            if param.requires_grad:\n",
    "                trainable_parameter += param.numel()\n",
    "                print(f\"✓ TRAINABLE: {name}\")\n",
    "            else:\n",
    "                print(f\"  Frozen: {name}\")\n",
    "        \n",
    "        print(f\"\\nTotal parameters: {total_parameter:,}\")\n",
    "        print(f\"Trainable parameters: {trainable_parameter:,}\")\n",
    "        print(f\"Percentage trainable: {100 * trainable_parameter / total_parameter:.2f}%\")\n",
    "        print('='*60)\n",
    "        \n",
    "        return trainable_parameter, total_parameter\n",
    "    \n",
    "    def get_model(self):\n",
    "        return self.model\n",
    "    \n",
    "    def get_feature_extractor(self):\n",
    "        if self.feature_extractor is None:\n",
    "            raise ValueError(\"Feature extractor not initialized. Call _feature_extractor() first.\")\n",
    "        return self.feature_extractor\n",
    "    \n",
    "    def save_model(self, path):\n",
    "        \"\"\"Save the important parameters and model details to use even after the training is done\"\"\"\n",
    "        \n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Cannot save: model is not initialized\")\n",
    "            \n",
    "        if self.feature_extractor is None:\n",
    "            raise ValueError(\"Cannot save: feature extractor is not initialized\")\n",
    "\n",
    "        trainable_names = [name for name, p in self.model.named_parameters() if p.requires_grad]\n",
    "\n",
    "        torch.save({\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'model_name': self.model_name,\n",
    "            'config': self.config.to_dict(),\n",
    "            'trainable_layers': trainable_names,\n",
    "            'feature_extractor_state_dict': self.feature_extractor.state_dict()\n",
    "        }, path)\n",
    "        \n",
    "        print(f\"Model saved to {path}\")\n",
    "                \n",
    "    def load_model(self, path):\n",
    "        \"\"\"Loading the saved model\"\"\"\n",
    "        \n",
    "        # First, ensure the model architecture is initialized\n",
    "        if self.model is None:\n",
    "            self._initialize_model_finetune()\n",
    "            \n",
    "        # FIX: Add weights_only=False to allow loading Config objects\n",
    "        checkpoint = torch.load(path, map_location=self.device, weights_only=False)\n",
    "        \n",
    "        # Load model state dictionary\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        \n",
    "        # Verify model name matches\n",
    "        if 'model_name' in checkpoint and checkpoint['model_name'] != self.model_name:\n",
    "            print(f\"Warning: Loading {checkpoint['model_name']} into {self.model_name}\")\n",
    "\n",
    "        # Loading the trainable parameter if in the model\n",
    "        if 'trainable_layers' in checkpoint:\n",
    "            # First freeze all\n",
    "            for param in self.model.parameters():\n",
    "                param.requires_grad = False\n",
    "            # Then unfreeze saved trainable layers\n",
    "            for name, param in self.model.named_parameters():\n",
    "                if name in checkpoint['trainable_layers']:\n",
    "                    param.requires_grad = True\n",
    "        \n",
    "        self._feature_extractor()\n",
    "        \n",
    "        print(f\"Model loaded from {path}\")\n",
    "        return self.model\n",
    "    \n",
    "    def debug_model_state(self):\n",
    "        \"\"\"Debug method to check model initialization\"\"\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Debug: {self.model_name}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"1. Model is None: {self.model is None}\")\n",
    "        print(f\"2. Feature extractor is None: {self.feature_extractor is None}\")\n",
    "        \n",
    "        if self.model is not None:\n",
    "            print(f\"3. Model type: {type(self.model)}\")\n",
    "            print(f\"4. Model has children: {hasattr(self.model, 'children')}\")\n",
    "            \n",
    "            if hasattr(self.model, 'children'):\n",
    "                children = list(self.model.children())\n",
    "                print(f\"5. Number of children: {len(children)}\")\n",
    "                print(f\"6. First 3 children types:\")\n",
    "                for i, child in enumerate(children[:3]):\n",
    "                    print(f\"   [{i}] {type(child).__name__}\")\n",
    "                if len(children) > 3:\n",
    "                    print(f\"   ... and {len(children)-3} more\")\n",
    "        \n",
    "        print(f\"{'='*60}\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f9be39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DRTrainer:\n",
    "    \"Training engine for our fine tune CNNs\"\n",
    "\n",
    "    def __init__(self, config, model_manager, trial=None):\n",
    "        self.config = config\n",
    "        self.model_manager = model_manager\n",
    "        self.model = self.model_manager.get_model()\n",
    "        self.device = self.config.device\n",
    "        self.trial = trial\n",
    "\n",
    "        #Printing the Trainable parameter information\n",
    "        self.model_manager.print_trainable_parameters()\n",
    "\n",
    "        training_params = [p for p in self.model.parameters() if p.requires_grad]\n",
    "\n",
    "        if training_params == 0:\n",
    "            raise ValueError(\"No training parameters found. Check the fine tuning.\")\n",
    "        \n",
    "        print(f\"\\nOptimizing {len(training_params)} parameter groups\")\n",
    "        \n",
    "        # Different learning rates for fine-tuned layers vs new layers\n",
    "        # Higher LR for new layers, lower LR for fine-tuned pretrained layers\n",
    "        \n",
    "        # Group parameters by type\n",
    "        new_layers = []\n",
    "        finetune_layers = []\n",
    "        \n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                if 'fc' in name or 'classifier' in name:\n",
    "                    new_layers.append(param)  # New classifier layers\n",
    "                else:\n",
    "                    finetune_layers.append(param)  # Fine-tuned pretrained layers\n",
    "        \n",
    "        # Create parameter groups with different learning rates\n",
    "        # We pass these groups to the optimizer\n",
    "        param_groups = [\n",
    "            {'params': finetune_layers, 'lr': config.learning_rate * 0.1},\n",
    "            {'params': new_layers, 'lr': config.learning_rate}  \n",
    "        ]\n",
    "        self.optimizer = optim.AdamW(param_groups, lr=config.learning_rate)\n",
    "        \n",
    "        #lr scheduler for countinuouly chaning learning and then restarting with higher after some epochs\n",
    "        # Scheduler: OneCycleLR is a smart learning rate scheduler that follows a specific policy:\n",
    "        # Warm up: Gradually increase learning rate from low to high\n",
    "        #Annealing: Gradually decrease learning rate from high to low\n",
    "        #Single cycle: All done in one complete cycle (hence the name)\n",
    "\n",
    "        self.scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "            self.optimizer, \n",
    "            max_lr=[config.learning_rate * 0.1, config.learning_rate],\n",
    "            epochs=config.num_epochs,\n",
    "            steps_per_epoch=115, # Approx batches (3662 / 32)\n",
    "            pct_start=0.3\n",
    "        )\n",
    "\n",
    "        # Loss fucntion with class wieght imbalance\n",
    "        self.criterion = self._get_weighted_loss()\n",
    "\n",
    "        #initialize GradScaler for mixed precision training if CUDA is available\n",
    "        self.scaler = torch.GradScaler('cuda') if torch.cuda.is_available() else None\n",
    "\n",
    "        self.history = {\n",
    "            'train_loss': [], 'train_acc': [],\n",
    "            'val_loss': [], 'val_acc': [],\n",
    "            'learning_rates': []\n",
    "        }\n",
    "\n",
    "    def _get_weighted_loss(self):\n",
    "        \"\"\"\n",
    "    Dynamically calculates class weights based on the training data.\n",
    "    Higher weights are assigned to rare classes (like Severe DR) to prevent bias.\n",
    "    \"\"\"\n",
    "        #Used to assign more weight to less frequency labels in the dataset to avoid baises\n",
    "        #Calculate the weight of each class by - Total sample / no.of classes * count of item in class i\n",
    "        if not self.config.train_csv.exists():\n",
    "            print(\"Warning: Train CSV not found for weight calc. Using default weights.\")\n",
    "            return nn.CrossEntropyLoss()\n",
    "        \n",
    "\n",
    "        df = pd.read_csv(self.config.train_csv)\n",
    "        # Count samples per class\n",
    "        counts = df[\"diagnosis\"].value_counts().sort_index()\n",
    "        class_counts = counts.values\n",
    "        # Calculate weights: Total / (Num_Classes * Class_Count)\n",
    "        # This is the standard \"Balanced\" formula\n",
    "        total_samples = sum(class_counts)\n",
    "        num_classes = len(class_counts)\n",
    "        weights = total_samples / (num_classes * class_counts)\n",
    "\n",
    "        class_weights = torch.tensor(weights, dtype=torch.float32)\n",
    "        #trunsout to be tensor([0.4058, 1.9795, 0.7331, 3.7948, 2.4827])\n",
    "        #Normalize weights\n",
    "        class_weights = class_weights / class_weights.sum()\n",
    "        class_weights = class_weights.to(self.device)\n",
    "\n",
    "        print(f\"Computed Class Weights: {class_weights}\")\n",
    "        # Expected Output for APTOS: tensor([0.05, 0.22, 0.08, 0.41, 0.24]) approx\n",
    "        return nn.CrossEntropyLoss(weight= class_weights)\n",
    "    \n",
    "    def train_epoch(self, train_loader, epoch):\n",
    "        self.model.train()\n",
    "\n",
    "        #Handling the BatchNorm blocks in fine tunning to make sure they are in traning mode\n",
    "        for name, module in self.model.named_modules():\n",
    "            if isinstance(module, nn.BatchNorm2d) and hasattr(module, 'weight'):\n",
    "                if module.weight.requires_grad:\n",
    "                    module.train()\n",
    "\n",
    "        running_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{self.config.num_epochs}')\n",
    "        for batch_idx, (inputs, labels) in enumerate(pbar):\n",
    "            inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "\n",
    "            #Handling the InceptionV3 duo outputs during training (output, aux_output)\n",
    "            # Adding autocast context for mixed precision compatibility\n",
    "            with torch.autocast('cuda', enabled=(self.scaler is not None)):\n",
    "                if self.model_manager.model_name == 'inceptionV3':\n",
    "                    outputs, aux_outputs = self.model(inputs)\n",
    "                    # outputs: Main prediction from final layer\n",
    "                    # aux_outputs: Auxiliary prediction from middle layer\n",
    "\n",
    "                    loss1 = self.criterion(outputs, labels)\n",
    "                    loss2 = self.criterion(aux_outputs, labels)\n",
    "                    loss = loss1 + 0.4 * loss2  # Weighted sum as in original paper\n",
    "                else:\n",
    "                    outputs = self.model(inputs)\n",
    "                    loss = self.criterion(outputs, labels)\n",
    "\n",
    "            # CONCEPT: Gradient Clipping\n",
    "            # Fine-tuning can sometimes produce large gradients that destabilize the\n",
    "            # pre-trained weights. We clip the gradient norm to 1.0 to ensure smooth updates.\n",
    "            #for faster training we use mix precision training where we use FP16 and Fp32\n",
    "            if self.scaler:  # If we have a GPU that supports mixed precision\n",
    "                # 1. Scale up the loss (prevents underflow)\n",
    "                self.scaler.scale(loss).backward()\n",
    "                # Loss is multiplied by e.g., 65536 before backward pass\n",
    "                \n",
    "                # 2. Unscale gradients before optimizer step\n",
    "                self.scaler.unscale_(self.optimizer)\n",
    "                # Now gradients are back to normal scale\n",
    "                \n",
    "                # 3. Clip gradients (prevent overflow)\n",
    "                torch.nn.utils.clip_grad_norm_(\n",
    "                    [p for p in self.model.parameters() if p.requires_grad], \n",
    "                    max_norm=1.0\n",
    "                )\n",
    "                \n",
    "                # 4. Optimizer step with scaling\n",
    "                self.scaler.step(self.optimizer)\n",
    "                \n",
    "                # 5. Update scale factor for next iteration\n",
    "                self.scaler.update()\n",
    "\n",
    "            else:\n",
    "                loss.backward()\n",
    "\n",
    "                #gradient Clipping \n",
    "                torch.nn.utils.clip_grad_norm_(\n",
    "                    [p for p in self.model.parameters() if p.requires_grad], \n",
    "                    max_norm=1.0)\n",
    "\n",
    "                self.optimizer.step()\n",
    "\n",
    "            #statistics\n",
    "            #running_loss: Sum of all batch losses in the current epoch\n",
    "            #Example: If 100 batches with losses [0.5, 0.4, 0.3, ...], running_loss = 0.5 + 0.4 + 0.3 + ...\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            #getting the prediction outputs where we recive 5 output and only choose max value from each iteration\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "\n",
    "            #Gettting the total correctly predicted labels in each iteration\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "            #showing the progress bar to monitor the performance\n",
    "            pbar.set_postfix({\n",
    "                'loss': running_loss / (batch_idx + 1),\n",
    "                'acc': 100. * correct / total\n",
    "            })\n",
    "\n",
    "        #Managing the loss per epcoh\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_acc = 100. * correct / total\n",
    "\n",
    "        self.history['train_loss'].append(epoch_loss)\n",
    "        self.history['train_acc'].append(epoch_acc)\n",
    "\n",
    "        return epoch_loss, epoch_acc\n",
    "    \n",
    "    def validate(self, val_loader):\n",
    "        #Performing the validation for our trained model\n",
    "        self.model.eval()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "\n",
    "                #For InceptionV3 in eval mode, no aux output\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "\n",
    "                running_loss = loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        epoch_loss = running_loss / len(val_loader)\n",
    "        epoch_acc = 100* correct/ total\n",
    "\n",
    "        self.history['val_loss'].append(epoch_loss)\n",
    "        self.history['val_acc'].append(epoch_acc)\n",
    "\n",
    "        return epoch_loss, epoch_acc, all_preds, all_labels\n",
    "    \n",
    "    def save_checkpoint(self, epoch, best_acc, save_path):\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'best_acc': best_acc,\n",
    "            'history': self.history\n",
    "        }, save_path)\n",
    "\n",
    "    def load_checkpoint(self, path):\n",
    "        ckpt = torch.load(path, map_location=self.device)\n",
    "        self.model.load_state_dict(ckpt['model_state_dict'])\n",
    "        self.optimizer.load_state_dict(ckpt['optimizer_state_dict'])\n",
    "        self.history = ckpt['history']\n",
    "        return ckpt['epoch'], ckpt['best_acc']\n",
    "        \n",
    "    def train(self, train_loader, val_loader, start_epoch=0, best_acc=0):\n",
    "        #Complete Traing loopwith fine tunning included\n",
    "\n",
    "        checkpoint_path = self.config.model_dir / f'{self.model_manager.model_name}_finetune_checkpoint.pth'\n",
    "        best_model_path = self.config.model_dir / f\"{self.model_manager.model_name}_finetune_best.pth\"\n",
    "\n",
    "        print(f\"\\nStarting fine-tunning for {self.model_manager.model_name}\")\n",
    "        print(f\"Checkpoint will be saved to: {checkpoint_path}\")\n",
    "\n",
    "        for epoch in range(start_epoch, self.config.num_epochs):\n",
    "            # Adjust learning rate if using warmup\n",
    "            if epoch < 5: # Warmup phase\n",
    "                for param_group in self.optimizer.param_groups:\n",
    "                    param_group['lr'] = self.config.learning_rate * (epoch + 1) / 5\n",
    "            \n",
    "            # --- CORRECTION: Training logic moved OUT of the warmup/param loop ---\n",
    "\n",
    "            # Train\n",
    "            train_loss, train_acc = self.train_epoch(train_loader, epoch)\n",
    "            \n",
    "            # Validate\n",
    "            val_loss, val_acc, val_preds, val_labels = self.validate(val_loader)\n",
    "\n",
    "            # Update the learning rate scheduler\n",
    "            self.scheduler.step(epoch + train_loss)\n",
    "\n",
    "            # storing learning rate\n",
    "            current_lr = self.optimizer.param_groups[0]['lr']\n",
    "            self.history['learning_rates'].append(current_lr)\n",
    "\n",
    "            # Save checkpoint\n",
    "            self.save_checkpoint(epoch, best_acc, checkpoint_path)\n",
    "\n",
    "            #Reporting intermidiate results to Optuna\n",
    "            if self.trial:\n",
    "                self.trial.report(val_acc, epoch)\n",
    "                #Handle pruning(stop this trial if it's not promising)\n",
    "                if self.trial.should_prune():\n",
    "                    raise optuna.TrialPruned()\n",
    "\n",
    "            # Save the best model\n",
    "            if val_acc > best_acc:\n",
    "                best_acc = val_acc\n",
    "                #Only save to disk if we are Not tuning(to save time), or if it's a really good model\n",
    "                #If self.trial is None, we are in normal training model -> always save.\n",
    "                if self.trial is None:\n",
    "                    self.model_manager.save_model(best_model_path)\n",
    "                    print(f\"New best model saved with accuracy: {best_acc:.2f}%\")\n",
    "                else:\n",
    "                    #In tuning mode, we might skip saving to disk to be faster, \n",
    "                    # unless you explicitly want to keep the best tuned models.\n",
    "                    # For now, I'll keep saving it so you don't lose the result.\n",
    "                    self.model_manager.save_model(best_model_path)\n",
    "                    print(f\"New best model saved with accuracy: {best_acc:.2f}%\")\n",
    "\n",
    "            print(f'\\nEpoch {epoch+1}/{self.config.num_epochs}:')\n",
    "            print(f'Train loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
    "            print(f'Val loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
    "\n",
    "            # Print learning rates for each parameter group\n",
    "            for i, param_group in enumerate(self.optimizer.param_groups):\n",
    "                if i == 0:\n",
    "                    print(f\"  Fine-tune LR: {param_group['lr']:.6f}\")\n",
    "                else:\n",
    "                    print(f\"  New layers LR: {param_group['lr']:.6f}\")\n",
    "            \n",
    "            print(\"-\" * 60)\n",
    "\n",
    "            #Stoping if the model reaches 95% accuracy in either training or validation\n",
    "            if train_acc > 95.0 or val_acc > 95.0:\n",
    "                print(f\"\\n{'='*40}\")\n",
    "                print(\"Traget of 95+ plus reached.\")\n",
    "                print(f\"Train:{train_acc:.2f}% | Val: {val_acc:.2f}%\")\n",
    "                print(f\"Stopping training early.\")\n",
    "                print(f\"{'='*40}\")\n",
    "\n",
    "                #Ensuring if the best model is saved if this final run was the best\n",
    "                if val_acc >= best_acc:\n",
    "                    self.model_manager.save_model(best_model_path)\n",
    "                    break\n",
    "        \n",
    "        \n",
    "        # --- CORRECTION: Final loading moved OUT of the epoch loop ---\n",
    "        # Load best model for final evaluation\n",
    "        self.model_manager.load_model(best_model_path)\n",
    "        print(f\"\\n✓ Fine-tuning completed for {self.model_manager.model_name}\")\n",
    "        print(f\"✓ Best validation accuracy: {best_acc:.2f}%\")\n",
    "        \n",
    "        return self.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "351cd3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor:\n",
    "    # Passes images through the trained CNN models (minus the final classification layer)\n",
    "    # to extract high-level feature vectors (embeddings). These vectors are then used \n",
    "    # as the input data to train the XGBoost classifier.\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.device = config.device\n",
    "\n",
    "    def extract_feature(self,model_manager, data_loader):\n",
    "        feature_extractor = model_manager.get_feature_extractor()\n",
    "        feature_extractor.eval()\n",
    "        all_features, all_labels = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in tqdm(data_loader, desc='Extracting features'):\n",
    "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "\n",
    "                features = feature_extractor(inputs)\n",
    "                features = features.view(features.size(0), -1)\n",
    "                all_features.append(features.cpu().numpy())\n",
    "                all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "        if len(all_features) == 0:\n",
    "            raise ValueError(\"No features extracted! Check your data loader.\")\n",
    "            \n",
    "        return np.vstack(all_features), np.concatenate(all_labels)        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6ad6ce6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XGBoostTrainer:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "\n",
    "    def train_single_model(self, X_train, y_train, X_val, y_val):\n",
    "        # FIX: Pass early_stopping_rounds to the constructor, NOT .fit()\n",
    "        model = xgb.XGBClassifier(\n",
    "            **self.config.xgb_params,\n",
    "            early_stopping_rounds=10, \n",
    "            eval_metric=\"mlogloss\"  # Required for multi-class early stopping\n",
    "        )\n",
    "        \n",
    "        # Train (verbose=False to keep output clean)\n",
    "        model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n",
    "        return model\n",
    "\n",
    "    def train_ensemble(self, feature_list, y_train, features_val_list, y_val):\n",
    "        X_train_combined = np.hstack(feature_list)\n",
    "        X_val_combined = np.hstack(features_val_list)\n",
    "        \n",
    "        # FIX: Pass early_stopping_rounds to the constructor here as well\n",
    "        model = xgb.XGBClassifier(\n",
    "            **self.config.xgb_params,\n",
    "            early_stopping_rounds=10,\n",
    "            eval_metric=\"mlogloss\"\n",
    "        )\n",
    "        \n",
    "        model.fit(X_train_combined, y_train, eval_set=[(X_val_combined, y_val)], verbose=False)\n",
    "        return model\n",
    "    \n",
    "    def evaluate_model(self, model, X_test, y_test, model_name):\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_proba = model.predict_proba(X_test)\n",
    "\n",
    "        metrics = {\n",
    "            'model_name': model_name,\n",
    "            'accuracy': accuracy_score(y_test, y_pred),\n",
    "            'f1_score': f1_score(y_test, y_pred, average='weighted'),\n",
    "            'cohen_kappa': cohen_kappa_score(y_test, y_pred),\n",
    "            'roc_auc': roc_auc_score(y_test, y_pred_proba, multi_class='ovr', average='weighted'),\n",
    "            'classification_report': classification_report(y_test, y_pred, output_dict=True)\n",
    "        }\n",
    "        return metrics, y_pred\n",
    "    \n",
    "    def save_model(self, model, model_name):\n",
    "        with open(self.config.model_dir/f'{model_name}_xgb.pkl', 'wb') as f:\n",
    "            pickle.dump(model, f)\n",
    "\n",
    "    def load_model(self, model_name):\n",
    "        with open(self.config.model_dir/ f\"{model_name}_xgb.pkl\", 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e4a8438b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResultsVisualizer:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        plt.style.use('seaborn-v0_8-darkgrid')\n",
    "    \n",
    "    def plot_training_history(self, history, model_name):\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "        axes[0].plot(history['train_loss'], label='Train')\n",
    "        axes[0].plot(history['val_loss'], label='Val')\n",
    "        axes[0].set_title('Loss')\n",
    "        axes[0].legend()\n",
    "        \n",
    "        axes[1].plot(history['train_acc'], label='Train')\n",
    "        axes[1].plot(history['val_acc'], label='Val')\n",
    "        axes[1].set_title('Accuracy')\n",
    "        \n",
    "        axes[2].plot(history['learning_rates'])\n",
    "        axes[2].set_title('Learning Rate')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.config.results_dir / f\"{model_name}_history.png\")\n",
    "        plt.close()\n",
    "\n",
    "    def save_metrics_report(self, metrics_dict):\n",
    "        with open(self.config.results_dir / \"metrics_report.json\", 'w') as f:\n",
    "            json.dump(metrics_dict, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "49f9865f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiabeticRetionpathyPipeline:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.model = {}\n",
    "        self.visualizer = ResultsVisualizer(config)\n",
    "        torch.manual_seed(self.config.random_seed)\n",
    "        np.random.seed(self.config.random_seed)\n",
    "        \n",
    "    def load_and_prepare_data(self):\n",
    "        print(\"Loading APTOS 2019 dataset...\")\n",
    "        \n",
    "        # 1. Load the CSV\n",
    "        df = pd.read_csv(self.config.train_csv)\n",
    "        print(f\"Original CSV size: {len(df)}\")\n",
    "        \n",
    "        # 2. --- NEW STEP: Filter out missing images ---\n",
    "        valid_rows = []\n",
    "        # Check extensions\n",
    "        extensions = ['.png', '.jpg', '.jpeg']\n",
    "        \n",
    "        print(\"Verifying image files...\")\n",
    "        for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Checking files\"):\n",
    "            img_id = row['id_code']\n",
    "            found = False\n",
    "            \n",
    "            # Check if file exists with any valid extension\n",
    "            for ext in extensions:\n",
    "                path = self.config.train_images_dir / f\"{img_id}{ext}\"\n",
    "                if path.exists():\n",
    "                    valid_rows.append(row)\n",
    "                    found = True\n",
    "                    break\n",
    "            \n",
    "            # Optional: Print the first missing one to debug\n",
    "            if not found and len(df) - len(valid_rows) == 1:\n",
    "                print(f\"Warning: Could not find image for ID: {img_id}\")\n",
    "\n",
    "        # Create new cleaned dataframe\n",
    "        df_clean = pd.DataFrame(valid_rows)\n",
    "        print(f\"Cleaned dataset size: {len(df_clean)} (Removed {len(df) - len(df_clean)} missing files)\")\n",
    "        \n",
    "        if len(df_clean) == 0:\n",
    "            raise ValueError(\"No valid images found! Check your paths.\")\n",
    "\n",
    "        # 3. Split data (Using the CLEAN dataframe)\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        train_df, val_df = train_test_split(\n",
    "            df_clean, # Use clean df\n",
    "            test_size=0.2, \n",
    "            random_state=self.config.random_seed,\n",
    "            stratify=df_clean['diagnosis']\n",
    "        )\n",
    "        \n",
    "        # 4. Create DataLoaders (Rest of your code is same)\n",
    "        train_loader = DataLoader(\n",
    "            CustomAptos(train_df, self.config.train_images_dir, DataAugmentation.get_train_transform()),\n",
    "            batch_size=self.config.batch_size, \n",
    "            shuffle=True, \n",
    "            num_workers=0, # Keep this 0 for Windows!\n",
    "            pin_memory=True,\n",
    "            drop_last=True\n",
    "        )\n",
    "        \n",
    "        val_loader = DataLoader(\n",
    "            CustomAptos(val_df, self.config.train_images_dir, DataAugmentation.get_val_transform()),\n",
    "            batch_size=self.config.batch_size, \n",
    "            shuffle=False, \n",
    "            num_workers=0, # Keep this 0 for Windows!\n",
    "            pin_memory=True,\n",
    "            drop_last=True #We drop the last batch if it has less images than the batch size\n",
    "        )\n",
    "        \n",
    "        return train_loader, val_loader\n",
    "    \n",
    "    def run_pipeline(self):\n",
    "        print(\"\\n===STARTING FINE-TUNED DR DETECTION PIPELINE===\")\n",
    "        \n",
    "        #1. Train Fine-Tunned CNNs\n",
    "        train_loader, val_loader = self.load_and_prepare_data()\n",
    "\n",
    "        for model_name in self.config.pretrained_models.keys():\n",
    "            #Check if model already exists to skip trainig\n",
    "            check_path = self.config.model_dir / f'{model_name}_finetune_best.pth'\n",
    "\n",
    "            manager = DRModelManager(self.config, model_name)\n",
    "\n",
    "            if check_path.exists():\n",
    "                print(f\"\\nFound existing wights for {model_name}. Loading the model.\")\n",
    "                manager.load_model(check_path)\n",
    "\n",
    "            else:\n",
    "                print(f\"\\nFine-Tuning {model_name}...\")\n",
    "                trainer = DRTrainer(self.config, manager)\n",
    "                histroy = trainer.train(train_loader, val_loader)\n",
    "                self.visualizer.plot_training_history(histroy, model_name)\n",
    "\n",
    "                #Free up memory from trainer\n",
    "                del trainer\n",
    "\n",
    "            #Load the best model we just saved to ensure we have the best state\n",
    "            manager.load_model(check_path)\n",
    "            self.model[model_name] = manager\n",
    "\n",
    "            torch.cuda.empty_cache() # Clear VRAM to avoid out of memory chrash for GPU(6GB)\n",
    "        \n",
    "        #2. Extract features\n",
    "        print(\"/nExtracting Feature for XGBoost...\")\n",
    "        feature_extractor = FeatureExtractor(self.config)\n",
    "        all_feature = {}\n",
    "\n",
    "        for model_name, manager in self.model.items():\n",
    "            print(f\"Extracting Features form {model_name}\")\n",
    "            \n",
    "            feats, labels = feature_extractor.extract_feature(manager, val_loader)\n",
    "            all_feature[model_name] = {'features': feats, 'labels': labels}\n",
    "\n",
    "        # 3. Train XGBoost Ensemble\n",
    "        print(\"\\nTraining XGBoost Ensemble...\")\n",
    "        xgb_trainer = XGBoostTrainer(self.config)\n",
    "        all_metrics = {}\n",
    "        \n",
    "        from sklearn.model_selection import train_test_split\n",
    "        \n",
    "        # Train Ensemble\n",
    "        X_combined_list, X_val_combined_list = [], []\n",
    "        y_train_all, y_test_all = None, None\n",
    "        \n",
    "        for model_name in self.model.keys():\n",
    "            feats, labels = all_feature[model_name]['features'], all_feature[model_name]['labels']\n",
    "            X_tr, X_te, y_tr, y_te = train_test_split(feats, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "            \n",
    "            # Train individual XGBoost for reporting\n",
    "            xgb_model = xgb_trainer.train_single_model(X_tr, y_tr, X_te, y_te)\n",
    "            metrics, _ = xgb_trainer.evaluate_model(xgb_model, X_te, y_te, f\"{model_name}_xgb\")\n",
    "            all_metrics[f\"{model_name}_xgb\"] = metrics\n",
    "            xgb_trainer.save_model(xgb_model, model_name)\n",
    "\n",
    "            X_combined_list.append(X_tr)\n",
    "            X_val_combined_list.append(X_te)\n",
    "            if y_train_all is None: y_train_all, y_test_all = y_tr, y_te\n",
    "\n",
    "        if not X_combined_list:\n",
    "            raise ValueError(\"No features were extracted. Pipeline cannot continue to Ensemble training.\")\n",
    "\n",
    "        # Train Ensemble XGBoost\n",
    "        ensemble_model = xgb_trainer.train_ensemble(X_combined_list, y_train_all, X_val_combined_list, y_test_all)\n",
    "        X_test_combined = np.hstack(X_val_combined_list)\n",
    "        metrics, _ = xgb_trainer.evaluate_model(ensemble_model, X_test_combined, y_test_all, 'ensemble_xgb')\n",
    "        all_metrics['ensemble_xgb'] = metrics\n",
    "        xgb_trainer.save_model(ensemble_model, 'ensemble')\n",
    "\n",
    "        #Final Report\n",
    "        self.visualizer.save_metrics_report(all_metrics)\n",
    "        print(\"\\n Pipeline Complete. Final Metrics:\")\n",
    "        print(json.dumps(all_metrics, indent=2))\n",
    "        return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "03ad4fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading APTOS 2019 dataset...\n",
      "Original CSV size: 3662\n",
      "Verifying image files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking files: 100%|██████████| 3662/3662 [00:00<00:00, 14300.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset size: 3662 (Removed 0 missing files)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x1beb93bcaa0>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x1beb93d8860>)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_instance = Config()\n",
    "Pipeline = DiabeticRetionpathyPipeline(config_instance)\n",
    "\n",
    "Pipeline.load_and_prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "499e9235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===STARTING FINE-TUNED DR DETECTION PIPELINE===\n",
      "Loading APTOS 2019 dataset...\n",
      "Original CSV size: 3662\n",
      "Verifying image files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking files: 100%|██████████| 3662/3662 [00:00<00:00, 20994.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset size: 3662 (Removed 0 missing files)\n",
      "\n",
      "Found existing wights for resnet50. Loading the model.\n",
      "Model loaded from savemodels\\resnet50_finetune_best.pth\n",
      "Model loaded from savemodels\\resnet50_finetune_best.pth\n",
      "DenseNet classifier type: <class 'torch.nn.modules.linear.Linear'>\n",
      "DenseNet classifier: Linear(in_features=1024, out_features=1000, bias=True)\n",
      "Created new classifier with 1024 input features\n",
      "New classifier architecture: Sequential(\n",
      "  (0): Dropout(p=0.5, inplace=False)\n",
      "  (1): Linear(in_features=1024, out_features=512, bias=True)\n",
      "  (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (3): ReLU(inplace=True)\n",
      "  (4): Dropout(p=0.3, inplace=False)\n",
      "  (5): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (6): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (7): ReLU(inplace=True)\n",
      "  (8): Dropout(p=0.2, inplace=False)\n",
      "  (9): Linear(in_features=256, out_features=5, bias=True)\n",
      ")\n",
      "\n",
      "Found existing wights for densenet121. Loading the model.\n",
      "Model loaded from savemodels\\densenet121_finetune_best.pth\n",
      "Model loaded from savemodels\\densenet121_finetune_best.pth\n",
      "\n",
      "Found existing wights for inceptionV3. Loading the model.\n",
      "Model loaded from savemodels\\inceptionV3_finetune_best.pth\n",
      "Model loaded from savemodels\\inceptionV3_finetune_best.pth\n",
      "/nExtracting Feature for XGBoost...\n",
      "Extracting Features form resnet50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████| 22/22 [02:02<00:00,  5.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Features form densenet121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████| 22/22 [02:22<00:00,  6.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Features form inceptionV3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████| 22/22 [02:34<00:00,  7.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training XGBoost Ensemble...\n",
      "\n",
      " Pipeline Complete. Final Metrics:\n",
      "{\n",
      "  \"resnet50_xgb\": {\n",
      "    \"model_name\": \"resnet50_xgb\",\n",
      "    \"accuracy\": 0.7872340425531915,\n",
      "    \"f1_score\": 0.7434641542397206,\n",
      "    \"cohen_kappa\": 0.6611120012818459,\n",
      "    \"roc_auc\": 0.9557554687631469,\n",
      "    \"classification_report\": {\n",
      "      \"0\": {\n",
      "        \"precision\": 0.9324324324324325,\n",
      "        \"recall\": 0.9857142857142858,\n",
      "        \"f1-score\": 0.9583333333333334,\n",
      "        \"support\": 70.0\n",
      "      },\n",
      "      \"1\": {\n",
      "        \"precision\": 0.5,\n",
      "        \"recall\": 0.07142857142857142,\n",
      "        \"f1-score\": 0.125,\n",
      "        \"support\": 14.0\n",
      "      },\n",
      "      \"2\": {\n",
      "        \"precision\": 0.6545454545454545,\n",
      "        \"recall\": 0.9473684210526315,\n",
      "        \"f1-score\": 0.7741935483870968,\n",
      "        \"support\": 38.0\n",
      "      },\n",
      "      \"3\": {\n",
      "        \"precision\": 0.6666666666666666,\n",
      "        \"recall\": 0.25,\n",
      "        \"f1-score\": 0.36363636363636365,\n",
      "        \"support\": 8.0\n",
      "      },\n",
      "      \"4\": {\n",
      "        \"precision\": 0.42857142857142855,\n",
      "        \"recall\": 0.2727272727272727,\n",
      "        \"f1-score\": 0.3333333333333333,\n",
      "        \"support\": 11.0\n",
      "      },\n",
      "      \"accuracy\": 0.7872340425531915,\n",
      "      \"macro avg\": {\n",
      "        \"precision\": 0.6364431964431964,\n",
      "        \"recall\": 0.5054477101845523,\n",
      "        \"f1-score\": 0.5108993157380255,\n",
      "        \"support\": 141.0\n",
      "      },\n",
      "      \"weighted avg\": {\n",
      "        \"precision\": 0.7602171389405432,\n",
      "        \"recall\": 0.7872340425531915,\n",
      "        \"f1-score\": 0.7434641542397206,\n",
      "        \"support\": 141.0\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"densenet121_xgb\": {\n",
      "    \"model_name\": \"densenet121_xgb\",\n",
      "    \"accuracy\": 0.7730496453900709,\n",
      "    \"f1_score\": 0.7309968583629625,\n",
      "    \"cohen_kappa\": 0.6382006254510464,\n",
      "    \"roc_auc\": 0.9419887376451966,\n",
      "    \"classification_report\": {\n",
      "      \"0\": {\n",
      "        \"precision\": 0.9066666666666666,\n",
      "        \"recall\": 0.9714285714285714,\n",
      "        \"f1-score\": 0.9379310344827586,\n",
      "        \"support\": 70.0\n",
      "      },\n",
      "      \"1\": {\n",
      "        \"precision\": 0.3333333333333333,\n",
      "        \"recall\": 0.14285714285714285,\n",
      "        \"f1-score\": 0.2,\n",
      "        \"support\": 14.0\n",
      "      },\n",
      "      \"2\": {\n",
      "        \"precision\": 0.660377358490566,\n",
      "        \"recall\": 0.9210526315789473,\n",
      "        \"f1-score\": 0.7692307692307693,\n",
      "        \"support\": 38.0\n",
      "      },\n",
      "      \"3\": {\n",
      "        \"precision\": 0.6,\n",
      "        \"recall\": 0.375,\n",
      "        \"f1-score\": 0.46153846153846156,\n",
      "        \"support\": 8.0\n",
      "      },\n",
      "      \"4\": {\n",
      "        \"precision\": 0.5,\n",
      "        \"recall\": 0.09090909090909091,\n",
      "        \"f1-score\": 0.15384615384615385,\n",
      "        \"support\": 11.0\n",
      "      },\n",
      "      \"accuracy\": 0.7730496453900709,\n",
      "      \"macro avg\": {\n",
      "        \"precision\": 0.6000754716981131,\n",
      "        \"recall\": 0.5002494873547505,\n",
      "        \"f1-score\": 0.5045092838196287,\n",
      "        \"support\": 141.0\n",
      "      },\n",
      "      \"weighted avg\": {\n",
      "        \"precision\": 0.7342388152906016,\n",
      "        \"recall\": 0.7730496453900709,\n",
      "        \"f1-score\": 0.7309968583629625,\n",
      "        \"support\": 141.0\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"inceptionV3_xgb\": {\n",
      "    \"model_name\": \"inceptionV3_xgb\",\n",
      "    \"accuracy\": 0.7304964539007093,\n",
      "    \"f1_score\": 0.6573298901084871,\n",
      "    \"cohen_kappa\": 0.564956154595648,\n",
      "    \"roc_auc\": 0.9112560686890321,\n",
      "    \"classification_report\": {\n",
      "      \"0\": {\n",
      "        \"precision\": 0.9178082191780822,\n",
      "        \"recall\": 0.9571428571428572,\n",
      "        \"f1-score\": 0.9370629370629371,\n",
      "        \"support\": 70.0\n",
      "      },\n",
      "      \"1\": {\n",
      "        \"precision\": 0.0,\n",
      "        \"recall\": 0.0,\n",
      "        \"f1-score\": 0.0,\n",
      "        \"support\": 14.0\n",
      "      },\n",
      "      \"2\": {\n",
      "        \"precision\": 0.5714285714285714,\n",
      "        \"recall\": 0.9473684210526315,\n",
      "        \"f1-score\": 0.7128712871287128,\n",
      "        \"support\": 38.0\n",
      "      },\n",
      "      \"3\": {\n",
      "        \"precision\": 0.0,\n",
      "        \"recall\": 0.0,\n",
      "        \"f1-score\": 0.0,\n",
      "        \"support\": 8.0\n",
      "      },\n",
      "      \"4\": {\n",
      "        \"precision\": 0.0,\n",
      "        \"recall\": 0.0,\n",
      "        \"f1-score\": 0.0,\n",
      "        \"support\": 11.0\n",
      "      },\n",
      "      \"accuracy\": 0.7304964539007093,\n",
      "      \"macro avg\": {\n",
      "        \"precision\": 0.2978473581213307,\n",
      "        \"recall\": 0.38090225563909774,\n",
      "        \"f1-score\": 0.32998684483832996,\n",
      "        \"support\": 141.0\n",
      "      },\n",
      "      \"weighted avg\": {\n",
      "        \"precision\": 0.6096514968563934,\n",
      "        \"recall\": 0.7304964539007093,\n",
      "        \"f1-score\": 0.6573298901084871,\n",
      "        \"support\": 141.0\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"ensemble_xgb\": {\n",
      "    \"model_name\": \"ensemble_xgb\",\n",
      "    \"accuracy\": 0.7872340425531915,\n",
      "    \"f1_score\": 0.7383944326704074,\n",
      "    \"cohen_kappa\": 0.6587058253993868,\n",
      "    \"roc_auc\": 0.9505875601724199,\n",
      "    \"classification_report\": {\n",
      "      \"0\": {\n",
      "        \"precision\": 0.9078947368421053,\n",
      "        \"recall\": 0.9857142857142858,\n",
      "        \"f1-score\": 0.9452054794520548,\n",
      "        \"support\": 70.0\n",
      "      },\n",
      "      \"1\": {\n",
      "        \"precision\": 1.0,\n",
      "        \"recall\": 0.07142857142857142,\n",
      "        \"f1-score\": 0.13333333333333333,\n",
      "        \"support\": 14.0\n",
      "      },\n",
      "      \"2\": {\n",
      "        \"precision\": 0.6666666666666666,\n",
      "        \"recall\": 0.9473684210526315,\n",
      "        \"f1-score\": 0.782608695652174,\n",
      "        \"support\": 38.0\n",
      "      },\n",
      "      \"3\": {\n",
      "        \"precision\": 0.3333333333333333,\n",
      "        \"recall\": 0.125,\n",
      "        \"f1-score\": 0.18181818181818182,\n",
      "        \"support\": 8.0\n",
      "      },\n",
      "      \"4\": {\n",
      "        \"precision\": 0.5714285714285714,\n",
      "        \"recall\": 0.36363636363636365,\n",
      "        \"f1-score\": 0.4444444444444444,\n",
      "        \"support\": 11.0\n",
      "      },\n",
      "      \"accuracy\": 0.7872340425531915,\n",
      "      \"macro avg\": {\n",
      "        \"precision\": 0.6958646616541353,\n",
      "        \"recall\": 0.49862952836637053,\n",
      "        \"f1-score\": 0.4974820269400377,\n",
      "        \"support\": 141.0\n",
      "      },\n",
      "      \"weighted avg\": {\n",
      "        \"precision\": 0.7931797579054018,\n",
      "        \"recall\": 0.7872340425531915,\n",
      "        \"f1-score\": 0.7383944326704074,\n",
      "        \"support\": 141.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pipeline.run_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7de4dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code is looking in: D:\\Machine learning\\Semester Project\\Final Year Project\\Diabetic Retinotopy\\Modular Implementation\\aptos2019-blindness-detection\\train_images\n",
      "✅ Directory exists.\n",
      "First 5 files found in folder:\n",
      "['000c1434d8d7.png', '001639a390f0.png', '0024cdab0c1e.png', '002c21358ce6.png', '005b95c28852.png']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# 1. Initialize your config\n",
    "config = Config()\n",
    "\n",
    "# 2. Print where the code THINKS the images are\n",
    "print(f\"Code is looking in: {config.train_images_dir.resolve()}\")\n",
    "\n",
    "# 3. Check if that folder actually exists\n",
    "if not config.train_images_dir.exists():\n",
    "    print(\"❌ ERROR: The directory does not exist!\")\n",
    "else:\n",
    "    print(\"✅ Directory exists.\")\n",
    "    # 4. List the first 5 files to see what they look like\n",
    "    print(\"First 5 files found in folder:\")\n",
    "    print(os.listdir(config.train_images_dir)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8575660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted successfully!\n"
     ]
    }
   ],
   "source": [
    "import nbformat\n",
    "from nbconvert import PythonExporter\n",
    "\n",
    "# Load notebook\n",
    "with open('DRpipline2.ipynb', 'r', encoding='utf-8') as f:\n",
    "    nb = nbformat.read(f, as_version=4)\n",
    "\n",
    "# Export to Python\n",
    "exporter = PythonExporter()\n",
    "python_code, _ = exporter.from_notebook_node(nb)\n",
    "\n",
    "# Save to file\n",
    "with open('DRpipline.py', 'w', encoding='utf-8') as f:\n",
    "    f.write(python_code)\n",
    "\n",
    "print(\"Converted successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
